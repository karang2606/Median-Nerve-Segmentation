{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "286fb767",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from parts import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "823395ae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import datetime\n",
    "import json\n",
    "import random\n",
    "import time\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset,DataLoader, DistributedSampler\n",
    "\n",
    "import datasets\n",
    "import util.misc as utils\n",
    "from datasets import build_dataset, get_coco_api_from_dataset\n",
    "from engine import evaluate, train_one_epoch\n",
    "from models import build_model\n",
    "# import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from models.segmentation import VisTRsegm\n",
    "import pycocotools.mask as mask_util\n",
    "from util.box_ops import box_xyxy_to_cxcywh\n",
    "##\n",
    "import glob\n",
    "import re\n",
    "import os\n",
    "from torchvision.ops import masks_to_boxes\n",
    "from PIL import Image\n",
    "from tqdm.notebook import tqdm\n",
    "import torchvision.transforms.functional as F\n",
    "from engine import train_one_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a012f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "pat=re.compile(\"(\\d+)\\D*$\")\n",
    "\n",
    "def key_func(x):\n",
    "    mat=pat.search(os.path.split(x)[-1]) # match last group of digits\n",
    "    if mat is None:\n",
    "        return x\n",
    "    return \"{:>10}\".format(mat.group(1)) # right align to 10 digits\n",
    "\n",
    "# train_file_dir = glob.glob('./aster_updated_data_22_01_2022/Train/*')\n",
    "train_file_dir = glob.glob('../Dissertation/aster_updated_data_22_01_2022/Train/*')\n",
    "\n",
    "n_frames = 36\n",
    "\n",
    "train_image_list = []\n",
    "train_mask_list = []\n",
    "\n",
    "for path in train_file_dir:\n",
    "    frames = sorted(glob.glob(path+'/*_0001_IMAGES/images/*.jpg'), key=key_func)\n",
    "    masks = sorted(glob.glob(path+'/*_0001_IMAGES/masks/*.png'), key=key_func)\n",
    "\n",
    "#     for i in range(35):\n",
    "    for i in range(len(frames)-n_frames+1):\n",
    "        train_image_list.append(frames[i:i+n_frames])\n",
    "        train_mask_list.append(masks[i:i+n_frames])\n",
    "#         train_mask_list.append(masks[i+n_frames-1])\n",
    "        \n",
    "test_file_dir = glob.glob('../Dissertation/aster_updated_data_22_01_2022/Test/*')\n",
    "test_image_list = []\n",
    "test_mask_list = []\n",
    "\n",
    "for path in test_file_dir:\n",
    "    frames = sorted(glob.glob(path+'/*_0001_IMAGES/images/*.jpg'), key=key_func)\n",
    "    masks = sorted(glob.glob(path+'/*_0001_IMAGES/masks/*.png'), key=key_func)\n",
    "\n",
    "#     for i in range(35):\n",
    "    for i in range(len(frames)-n_frames+1):\n",
    "        test_image_list.append(frames[i:i+n_frames])\n",
    "        test_mask_list.append(masks[i:i+n_frames])\n",
    "#         test_mask_list.append(masks[i+n_frames-1])      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "683c1ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_transform(image_set):\n",
    "    normalize = T.Compose([\n",
    "        T.ToTensor(),\n",
    "        T.Normalize([0.2316], [0.2038]) #mean #standard deviation\n",
    "    ])\n",
    "    if image_set == 'train':\n",
    "        return T.Compose([\n",
    "            T.RandomHorizontalFlip(),\n",
    "            normalize,\n",
    "        ])\n",
    "\n",
    "    if image_set == 'val':\n",
    "        return T.Compose([normalize])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bb8955d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bbox(mask_list):\n",
    "    return torch.cat([masks_to_boxes(mask) for mask in mask_list], dim=0)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "490c9106",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImagePathDataset(Dataset):\n",
    "    def __init__(self, image_path, mask_path, n_frames, transform=None):\n",
    "        self.image_path = image_path\n",
    "        self.mask_path = mask_path\n",
    "        self.n_frames = n_frames\n",
    "        self.transform = transform\n",
    "        \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_path)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        image = [Image.open(self.image_path[idx][i]) for i in range(self.n_frames)]\n",
    "        mask = [F.to_tensor(Image.open(self.mask_path[idx][i]))\n",
    "                for i in range(self.n_frames)]\n",
    "        \n",
    "        target = {}\n",
    "        target['labels'] = torch.ones(36).long()\n",
    "        target['valid'] = torch.ones(36).long()\n",
    "        target['masks'] = torch.cat(mask, dim=0)\n",
    "        target['boxes'] = get_bbox(mask)\n",
    "        \n",
    "        if self.transform is not None:\n",
    "            image, target = self.transform(image, target)\n",
    "        \n",
    "        image = [img.repeat(3,1,1) for img in image]\n",
    "            \n",
    "        return torch.cat(image,dim=0), target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cf3c5c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser('VisTR training and evaluation script',\n",
    "                                 parents=[get_args_parser()])\n",
    "args = parser.parse_args(\"\")\n",
    "args\n",
    "if args.output_dir:\n",
    "    Path(args.output_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# args.pretrained_weights = 'pretrained/r101.pth'\n",
    "args.masks = True\n",
    "args.device = 'cuda:1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3b69621",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import torch.utils.data\n",
    "# import torchvision\n",
    "# from pycocotools.ytvos import YTVOS\n",
    "# from pycocotools.ytvoseval import YTVOSeval\n",
    "# import datasets.transforms as T\n",
    "# from pycocotools import mask as coco_mask\n",
    "# import os\n",
    "# from PIL import Image\n",
    "# from random import randint\n",
    "# import cv2\n",
    "# import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8b1f9dc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not using distributed mode\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/karan/anaconda3/envs/tr/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/karan/anaconda3/envs/tr/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet101_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet101_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of params: 75709217\n"
     ]
    }
   ],
   "source": [
    "utils.init_distributed_mode(args)\n",
    "# print(\"git:\\n  {}\\n\".format(utils.get_sha()))\n",
    "device = torch.device(args.device)\n",
    "\n",
    "# fix the seed for reproducibility\n",
    "seed = args.seed + utils.get_rank()\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "\n",
    "model, criterion, postprocessors = build_model(args)\n",
    "model.to(device)\n",
    "\n",
    "model_without_ddp = model\n",
    "if args.distributed:\n",
    "    model = torch.nn.parallel.DistributedDataParallel(model, device_ids=[args.gpu])\n",
    "    model_without_ddp = model.module\n",
    "n_parameters = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print('number of params:', n_parameters)\n",
    "\n",
    "param_dicts = [\n",
    "    {\"params\": [p for n, p in model_without_ddp.named_parameters() if \"backbone\" not in n and p.requires_grad]},\n",
    "    {\n",
    "        \"params\": [p for n, p in model_without_ddp.named_parameters() if \"backbone\" in n and p.requires_grad],\n",
    "        \"lr\": args.lr_backbone,\n",
    "    },\n",
    "]\n",
    "optimizer = torch.optim.AdamW(param_dicts, lr=args.lr,\n",
    "                              weight_decay=args.weight_decay)\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, args.lr_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "042f2139",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['vistr.transformer.encoder.layers.0.self_attn.in_proj_weight', 'vistr.transformer.encoder.layers.0.self_attn.in_proj_bias', 'vistr.transformer.encoder.layers.0.self_attn.out_proj.weight', 'vistr.transformer.encoder.layers.0.self_attn.out_proj.bias', 'vistr.transformer.encoder.layers.0.linear1.weight', 'vistr.transformer.encoder.layers.0.linear1.bias', 'vistr.transformer.encoder.layers.0.linear2.weight', 'vistr.transformer.encoder.layers.0.linear2.bias', 'vistr.transformer.encoder.layers.0.norm1.weight', 'vistr.transformer.encoder.layers.0.norm1.bias', 'vistr.transformer.encoder.layers.0.norm2.weight', 'vistr.transformer.encoder.layers.0.norm2.bias', 'vistr.transformer.encoder.layers.1.self_attn.in_proj_weight', 'vistr.transformer.encoder.layers.1.self_attn.in_proj_bias', 'vistr.transformer.encoder.layers.1.self_attn.out_proj.weight', 'vistr.transformer.encoder.layers.1.self_attn.out_proj.bias', 'vistr.transformer.encoder.layers.1.linear1.weight', 'vistr.transformer.encoder.layers.1.linear1.bias', 'vistr.transformer.encoder.layers.1.linear2.weight', 'vistr.transformer.encoder.layers.1.linear2.bias', 'vistr.transformer.encoder.layers.1.norm1.weight', 'vistr.transformer.encoder.layers.1.norm1.bias', 'vistr.transformer.encoder.layers.1.norm2.weight', 'vistr.transformer.encoder.layers.1.norm2.bias', 'vistr.transformer.encoder.layers.2.self_attn.in_proj_weight', 'vistr.transformer.encoder.layers.2.self_attn.in_proj_bias', 'vistr.transformer.encoder.layers.2.self_attn.out_proj.weight', 'vistr.transformer.encoder.layers.2.self_attn.out_proj.bias', 'vistr.transformer.encoder.layers.2.linear1.weight', 'vistr.transformer.encoder.layers.2.linear1.bias', 'vistr.transformer.encoder.layers.2.linear2.weight', 'vistr.transformer.encoder.layers.2.linear2.bias', 'vistr.transformer.encoder.layers.2.norm1.weight', 'vistr.transformer.encoder.layers.2.norm1.bias', 'vistr.transformer.encoder.layers.2.norm2.weight', 'vistr.transformer.encoder.layers.2.norm2.bias', 'vistr.transformer.encoder.layers.3.self_attn.in_proj_weight', 'vistr.transformer.encoder.layers.3.self_attn.in_proj_bias', 'vistr.transformer.encoder.layers.3.self_attn.out_proj.weight', 'vistr.transformer.encoder.layers.3.self_attn.out_proj.bias', 'vistr.transformer.encoder.layers.3.linear1.weight', 'vistr.transformer.encoder.layers.3.linear1.bias', 'vistr.transformer.encoder.layers.3.linear2.weight', 'vistr.transformer.encoder.layers.3.linear2.bias', 'vistr.transformer.encoder.layers.3.norm1.weight', 'vistr.transformer.encoder.layers.3.norm1.bias', 'vistr.transformer.encoder.layers.3.norm2.weight', 'vistr.transformer.encoder.layers.3.norm2.bias', 'vistr.transformer.encoder.layers.4.self_attn.in_proj_weight', 'vistr.transformer.encoder.layers.4.self_attn.in_proj_bias', 'vistr.transformer.encoder.layers.4.self_attn.out_proj.weight', 'vistr.transformer.encoder.layers.4.self_attn.out_proj.bias', 'vistr.transformer.encoder.layers.4.linear1.weight', 'vistr.transformer.encoder.layers.4.linear1.bias', 'vistr.transformer.encoder.layers.4.linear2.weight', 'vistr.transformer.encoder.layers.4.linear2.bias', 'vistr.transformer.encoder.layers.4.norm1.weight', 'vistr.transformer.encoder.layers.4.norm1.bias', 'vistr.transformer.encoder.layers.4.norm2.weight', 'vistr.transformer.encoder.layers.4.norm2.bias', 'vistr.transformer.encoder.layers.5.self_attn.in_proj_weight', 'vistr.transformer.encoder.layers.5.self_attn.in_proj_bias', 'vistr.transformer.encoder.layers.5.self_attn.out_proj.weight', 'vistr.transformer.encoder.layers.5.self_attn.out_proj.bias', 'vistr.transformer.encoder.layers.5.linear1.weight', 'vistr.transformer.encoder.layers.5.linear1.bias', 'vistr.transformer.encoder.layers.5.linear2.weight', 'vistr.transformer.encoder.layers.5.linear2.bias', 'vistr.transformer.encoder.layers.5.norm1.weight', 'vistr.transformer.encoder.layers.5.norm1.bias', 'vistr.transformer.encoder.layers.5.norm2.weight', 'vistr.transformer.encoder.layers.5.norm2.bias', 'vistr.transformer.decoder.layers.0.self_attn.in_proj_weight', 'vistr.transformer.decoder.layers.0.self_attn.in_proj_bias', 'vistr.transformer.decoder.layers.0.self_attn.out_proj.weight', 'vistr.transformer.decoder.layers.0.self_attn.out_proj.bias', 'vistr.transformer.decoder.layers.0.multihead_attn.in_proj_weight', 'vistr.transformer.decoder.layers.0.multihead_attn.in_proj_bias', 'vistr.transformer.decoder.layers.0.multihead_attn.out_proj.weight', 'vistr.transformer.decoder.layers.0.multihead_attn.out_proj.bias', 'vistr.transformer.decoder.layers.0.linear1.weight', 'vistr.transformer.decoder.layers.0.linear1.bias', 'vistr.transformer.decoder.layers.0.linear2.weight', 'vistr.transformer.decoder.layers.0.linear2.bias', 'vistr.transformer.decoder.layers.0.norm1.weight', 'vistr.transformer.decoder.layers.0.norm1.bias', 'vistr.transformer.decoder.layers.0.norm2.weight', 'vistr.transformer.decoder.layers.0.norm2.bias', 'vistr.transformer.decoder.layers.0.norm3.weight', 'vistr.transformer.decoder.layers.0.norm3.bias', 'vistr.transformer.decoder.layers.1.self_attn.in_proj_weight', 'vistr.transformer.decoder.layers.1.self_attn.in_proj_bias', 'vistr.transformer.decoder.layers.1.self_attn.out_proj.weight', 'vistr.transformer.decoder.layers.1.self_attn.out_proj.bias', 'vistr.transformer.decoder.layers.1.multihead_attn.in_proj_weight', 'vistr.transformer.decoder.layers.1.multihead_attn.in_proj_bias', 'vistr.transformer.decoder.layers.1.multihead_attn.out_proj.weight', 'vistr.transformer.decoder.layers.1.multihead_attn.out_proj.bias', 'vistr.transformer.decoder.layers.1.linear1.weight', 'vistr.transformer.decoder.layers.1.linear1.bias', 'vistr.transformer.decoder.layers.1.linear2.weight', 'vistr.transformer.decoder.layers.1.linear2.bias', 'vistr.transformer.decoder.layers.1.norm1.weight', 'vistr.transformer.decoder.layers.1.norm1.bias', 'vistr.transformer.decoder.layers.1.norm2.weight', 'vistr.transformer.decoder.layers.1.norm2.bias', 'vistr.transformer.decoder.layers.1.norm3.weight', 'vistr.transformer.decoder.layers.1.norm3.bias', 'vistr.transformer.decoder.layers.2.self_attn.in_proj_weight', 'vistr.transformer.decoder.layers.2.self_attn.in_proj_bias', 'vistr.transformer.decoder.layers.2.self_attn.out_proj.weight', 'vistr.transformer.decoder.layers.2.self_attn.out_proj.bias', 'vistr.transformer.decoder.layers.2.multihead_attn.in_proj_weight', 'vistr.transformer.decoder.layers.2.multihead_attn.in_proj_bias', 'vistr.transformer.decoder.layers.2.multihead_attn.out_proj.weight', 'vistr.transformer.decoder.layers.2.multihead_attn.out_proj.bias', 'vistr.transformer.decoder.layers.2.linear1.weight', 'vistr.transformer.decoder.layers.2.linear1.bias', 'vistr.transformer.decoder.layers.2.linear2.weight', 'vistr.transformer.decoder.layers.2.linear2.bias', 'vistr.transformer.decoder.layers.2.norm1.weight', 'vistr.transformer.decoder.layers.2.norm1.bias', 'vistr.transformer.decoder.layers.2.norm2.weight', 'vistr.transformer.decoder.layers.2.norm2.bias', 'vistr.transformer.decoder.layers.2.norm3.weight', 'vistr.transformer.decoder.layers.2.norm3.bias', 'vistr.transformer.decoder.layers.3.self_attn.in_proj_weight', 'vistr.transformer.decoder.layers.3.self_attn.in_proj_bias', 'vistr.transformer.decoder.layers.3.self_attn.out_proj.weight', 'vistr.transformer.decoder.layers.3.self_attn.out_proj.bias', 'vistr.transformer.decoder.layers.3.multihead_attn.in_proj_weight', 'vistr.transformer.decoder.layers.3.multihead_attn.in_proj_bias', 'vistr.transformer.decoder.layers.3.multihead_attn.out_proj.weight', 'vistr.transformer.decoder.layers.3.multihead_attn.out_proj.bias', 'vistr.transformer.decoder.layers.3.linear1.weight', 'vistr.transformer.decoder.layers.3.linear1.bias', 'vistr.transformer.decoder.layers.3.linear2.weight', 'vistr.transformer.decoder.layers.3.linear2.bias', 'vistr.transformer.decoder.layers.3.norm1.weight', 'vistr.transformer.decoder.layers.3.norm1.bias', 'vistr.transformer.decoder.layers.3.norm2.weight', 'vistr.transformer.decoder.layers.3.norm2.bias', 'vistr.transformer.decoder.layers.3.norm3.weight', 'vistr.transformer.decoder.layers.3.norm3.bias', 'vistr.transformer.decoder.layers.4.self_attn.in_proj_weight', 'vistr.transformer.decoder.layers.4.self_attn.in_proj_bias', 'vistr.transformer.decoder.layers.4.self_attn.out_proj.weight', 'vistr.transformer.decoder.layers.4.self_attn.out_proj.bias', 'vistr.transformer.decoder.layers.4.multihead_attn.in_proj_weight', 'vistr.transformer.decoder.layers.4.multihead_attn.in_proj_bias', 'vistr.transformer.decoder.layers.4.multihead_attn.out_proj.weight', 'vistr.transformer.decoder.layers.4.multihead_attn.out_proj.bias', 'vistr.transformer.decoder.layers.4.linear1.weight', 'vistr.transformer.decoder.layers.4.linear1.bias', 'vistr.transformer.decoder.layers.4.linear2.weight', 'vistr.transformer.decoder.layers.4.linear2.bias', 'vistr.transformer.decoder.layers.4.norm1.weight', 'vistr.transformer.decoder.layers.4.norm1.bias', 'vistr.transformer.decoder.layers.4.norm2.weight', 'vistr.transformer.decoder.layers.4.norm2.bias', 'vistr.transformer.decoder.layers.4.norm3.weight', 'vistr.transformer.decoder.layers.4.norm3.bias', 'vistr.transformer.decoder.layers.5.self_attn.in_proj_weight', 'vistr.transformer.decoder.layers.5.self_attn.in_proj_bias', 'vistr.transformer.decoder.layers.5.self_attn.out_proj.weight', 'vistr.transformer.decoder.layers.5.self_attn.out_proj.bias', 'vistr.transformer.decoder.layers.5.multihead_attn.in_proj_weight', 'vistr.transformer.decoder.layers.5.multihead_attn.in_proj_bias', 'vistr.transformer.decoder.layers.5.multihead_attn.out_proj.weight', 'vistr.transformer.decoder.layers.5.multihead_attn.out_proj.bias', 'vistr.transformer.decoder.layers.5.linear1.weight', 'vistr.transformer.decoder.layers.5.linear1.bias', 'vistr.transformer.decoder.layers.5.linear2.weight', 'vistr.transformer.decoder.layers.5.linear2.bias', 'vistr.transformer.decoder.layers.5.norm1.weight', 'vistr.transformer.decoder.layers.5.norm1.bias', 'vistr.transformer.decoder.layers.5.norm2.weight', 'vistr.transformer.decoder.layers.5.norm2.bias', 'vistr.transformer.decoder.layers.5.norm3.weight', 'vistr.transformer.decoder.layers.5.norm3.bias', 'vistr.transformer.decoder.norm.weight', 'vistr.transformer.decoder.norm.bias', 'vistr.class_embed.weight', 'vistr.class_embed.bias', 'vistr.bbox_embed.layers.0.weight', 'vistr.bbox_embed.layers.0.bias', 'vistr.bbox_embed.layers.1.weight', 'vistr.bbox_embed.layers.1.bias', 'vistr.bbox_embed.layers.2.weight', 'vistr.bbox_embed.layers.2.bias', 'vistr.query_embed.weight', 'vistr.input_proj.weight', 'vistr.input_proj.bias', 'vistr.backbone.0.body.conv1.weight', 'vistr.backbone.0.body.bn1.weight', 'vistr.backbone.0.body.bn1.bias', 'vistr.backbone.0.body.bn1.running_mean', 'vistr.backbone.0.body.bn1.running_var', 'vistr.backbone.0.body.layer1.0.conv1.weight', 'vistr.backbone.0.body.layer1.0.bn1.weight', 'vistr.backbone.0.body.layer1.0.bn1.bias', 'vistr.backbone.0.body.layer1.0.bn1.running_mean', 'vistr.backbone.0.body.layer1.0.bn1.running_var', 'vistr.backbone.0.body.layer1.0.conv2.weight', 'vistr.backbone.0.body.layer1.0.bn2.weight', 'vistr.backbone.0.body.layer1.0.bn2.bias', 'vistr.backbone.0.body.layer1.0.bn2.running_mean', 'vistr.backbone.0.body.layer1.0.bn2.running_var', 'vistr.backbone.0.body.layer1.0.conv3.weight', 'vistr.backbone.0.body.layer1.0.bn3.weight', 'vistr.backbone.0.body.layer1.0.bn3.bias', 'vistr.backbone.0.body.layer1.0.bn3.running_mean', 'vistr.backbone.0.body.layer1.0.bn3.running_var', 'vistr.backbone.0.body.layer1.0.downsample.0.weight', 'vistr.backbone.0.body.layer1.0.downsample.1.weight', 'vistr.backbone.0.body.layer1.0.downsample.1.bias', 'vistr.backbone.0.body.layer1.0.downsample.1.running_mean', 'vistr.backbone.0.body.layer1.0.downsample.1.running_var', 'vistr.backbone.0.body.layer1.1.conv1.weight', 'vistr.backbone.0.body.layer1.1.bn1.weight', 'vistr.backbone.0.body.layer1.1.bn1.bias', 'vistr.backbone.0.body.layer1.1.bn1.running_mean', 'vistr.backbone.0.body.layer1.1.bn1.running_var', 'vistr.backbone.0.body.layer1.1.conv2.weight', 'vistr.backbone.0.body.layer1.1.bn2.weight', 'vistr.backbone.0.body.layer1.1.bn2.bias', 'vistr.backbone.0.body.layer1.1.bn2.running_mean', 'vistr.backbone.0.body.layer1.1.bn2.running_var', 'vistr.backbone.0.body.layer1.1.conv3.weight', 'vistr.backbone.0.body.layer1.1.bn3.weight', 'vistr.backbone.0.body.layer1.1.bn3.bias', 'vistr.backbone.0.body.layer1.1.bn3.running_mean', 'vistr.backbone.0.body.layer1.1.bn3.running_var', 'vistr.backbone.0.body.layer1.2.conv1.weight', 'vistr.backbone.0.body.layer1.2.bn1.weight', 'vistr.backbone.0.body.layer1.2.bn1.bias', 'vistr.backbone.0.body.layer1.2.bn1.running_mean', 'vistr.backbone.0.body.layer1.2.bn1.running_var', 'vistr.backbone.0.body.layer1.2.conv2.weight', 'vistr.backbone.0.body.layer1.2.bn2.weight', 'vistr.backbone.0.body.layer1.2.bn2.bias', 'vistr.backbone.0.body.layer1.2.bn2.running_mean', 'vistr.backbone.0.body.layer1.2.bn2.running_var', 'vistr.backbone.0.body.layer1.2.conv3.weight', 'vistr.backbone.0.body.layer1.2.bn3.weight', 'vistr.backbone.0.body.layer1.2.bn3.bias', 'vistr.backbone.0.body.layer1.2.bn3.running_mean', 'vistr.backbone.0.body.layer1.2.bn3.running_var', 'vistr.backbone.0.body.layer2.0.conv1.weight', 'vistr.backbone.0.body.layer2.0.bn1.weight', 'vistr.backbone.0.body.layer2.0.bn1.bias', 'vistr.backbone.0.body.layer2.0.bn1.running_mean', 'vistr.backbone.0.body.layer2.0.bn1.running_var', 'vistr.backbone.0.body.layer2.0.conv2.weight', 'vistr.backbone.0.body.layer2.0.bn2.weight', 'vistr.backbone.0.body.layer2.0.bn2.bias', 'vistr.backbone.0.body.layer2.0.bn2.running_mean', 'vistr.backbone.0.body.layer2.0.bn2.running_var', 'vistr.backbone.0.body.layer2.0.conv3.weight', 'vistr.backbone.0.body.layer2.0.bn3.weight', 'vistr.backbone.0.body.layer2.0.bn3.bias', 'vistr.backbone.0.body.layer2.0.bn3.running_mean', 'vistr.backbone.0.body.layer2.0.bn3.running_var', 'vistr.backbone.0.body.layer2.0.downsample.0.weight', 'vistr.backbone.0.body.layer2.0.downsample.1.weight', 'vistr.backbone.0.body.layer2.0.downsample.1.bias', 'vistr.backbone.0.body.layer2.0.downsample.1.running_mean', 'vistr.backbone.0.body.layer2.0.downsample.1.running_var', 'vistr.backbone.0.body.layer2.1.conv1.weight', 'vistr.backbone.0.body.layer2.1.bn1.weight', 'vistr.backbone.0.body.layer2.1.bn1.bias', 'vistr.backbone.0.body.layer2.1.bn1.running_mean', 'vistr.backbone.0.body.layer2.1.bn1.running_var', 'vistr.backbone.0.body.layer2.1.conv2.weight', 'vistr.backbone.0.body.layer2.1.bn2.weight', 'vistr.backbone.0.body.layer2.1.bn2.bias', 'vistr.backbone.0.body.layer2.1.bn2.running_mean', 'vistr.backbone.0.body.layer2.1.bn2.running_var', 'vistr.backbone.0.body.layer2.1.conv3.weight', 'vistr.backbone.0.body.layer2.1.bn3.weight', 'vistr.backbone.0.body.layer2.1.bn3.bias', 'vistr.backbone.0.body.layer2.1.bn3.running_mean', 'vistr.backbone.0.body.layer2.1.bn3.running_var', 'vistr.backbone.0.body.layer2.2.conv1.weight', 'vistr.backbone.0.body.layer2.2.bn1.weight', 'vistr.backbone.0.body.layer2.2.bn1.bias', 'vistr.backbone.0.body.layer2.2.bn1.running_mean', 'vistr.backbone.0.body.layer2.2.bn1.running_var', 'vistr.backbone.0.body.layer2.2.conv2.weight', 'vistr.backbone.0.body.layer2.2.bn2.weight', 'vistr.backbone.0.body.layer2.2.bn2.bias', 'vistr.backbone.0.body.layer2.2.bn2.running_mean', 'vistr.backbone.0.body.layer2.2.bn2.running_var', 'vistr.backbone.0.body.layer2.2.conv3.weight', 'vistr.backbone.0.body.layer2.2.bn3.weight', 'vistr.backbone.0.body.layer2.2.bn3.bias', 'vistr.backbone.0.body.layer2.2.bn3.running_mean', 'vistr.backbone.0.body.layer2.2.bn3.running_var', 'vistr.backbone.0.body.layer2.3.conv1.weight', 'vistr.backbone.0.body.layer2.3.bn1.weight', 'vistr.backbone.0.body.layer2.3.bn1.bias', 'vistr.backbone.0.body.layer2.3.bn1.running_mean', 'vistr.backbone.0.body.layer2.3.bn1.running_var', 'vistr.backbone.0.body.layer2.3.conv2.weight', 'vistr.backbone.0.body.layer2.3.bn2.weight', 'vistr.backbone.0.body.layer2.3.bn2.bias', 'vistr.backbone.0.body.layer2.3.bn2.running_mean', 'vistr.backbone.0.body.layer2.3.bn2.running_var', 'vistr.backbone.0.body.layer2.3.conv3.weight', 'vistr.backbone.0.body.layer2.3.bn3.weight', 'vistr.backbone.0.body.layer2.3.bn3.bias', 'vistr.backbone.0.body.layer2.3.bn3.running_mean', 'vistr.backbone.0.body.layer2.3.bn3.running_var', 'vistr.backbone.0.body.layer3.0.conv1.weight', 'vistr.backbone.0.body.layer3.0.bn1.weight', 'vistr.backbone.0.body.layer3.0.bn1.bias', 'vistr.backbone.0.body.layer3.0.bn1.running_mean', 'vistr.backbone.0.body.layer3.0.bn1.running_var', 'vistr.backbone.0.body.layer3.0.conv2.weight', 'vistr.backbone.0.body.layer3.0.bn2.weight', 'vistr.backbone.0.body.layer3.0.bn2.bias', 'vistr.backbone.0.body.layer3.0.bn2.running_mean', 'vistr.backbone.0.body.layer3.0.bn2.running_var', 'vistr.backbone.0.body.layer3.0.conv3.weight', 'vistr.backbone.0.body.layer3.0.bn3.weight', 'vistr.backbone.0.body.layer3.0.bn3.bias', 'vistr.backbone.0.body.layer3.0.bn3.running_mean', 'vistr.backbone.0.body.layer3.0.bn3.running_var', 'vistr.backbone.0.body.layer3.0.downsample.0.weight', 'vistr.backbone.0.body.layer3.0.downsample.1.weight', 'vistr.backbone.0.body.layer3.0.downsample.1.bias', 'vistr.backbone.0.body.layer3.0.downsample.1.running_mean', 'vistr.backbone.0.body.layer3.0.downsample.1.running_var', 'vistr.backbone.0.body.layer3.1.conv1.weight', 'vistr.backbone.0.body.layer3.1.bn1.weight', 'vistr.backbone.0.body.layer3.1.bn1.bias', 'vistr.backbone.0.body.layer3.1.bn1.running_mean', 'vistr.backbone.0.body.layer3.1.bn1.running_var', 'vistr.backbone.0.body.layer3.1.conv2.weight', 'vistr.backbone.0.body.layer3.1.bn2.weight', 'vistr.backbone.0.body.layer3.1.bn2.bias', 'vistr.backbone.0.body.layer3.1.bn2.running_mean', 'vistr.backbone.0.body.layer3.1.bn2.running_var', 'vistr.backbone.0.body.layer3.1.conv3.weight', 'vistr.backbone.0.body.layer3.1.bn3.weight', 'vistr.backbone.0.body.layer3.1.bn3.bias', 'vistr.backbone.0.body.layer3.1.bn3.running_mean', 'vistr.backbone.0.body.layer3.1.bn3.running_var', 'vistr.backbone.0.body.layer3.2.conv1.weight', 'vistr.backbone.0.body.layer3.2.bn1.weight', 'vistr.backbone.0.body.layer3.2.bn1.bias', 'vistr.backbone.0.body.layer3.2.bn1.running_mean', 'vistr.backbone.0.body.layer3.2.bn1.running_var', 'vistr.backbone.0.body.layer3.2.conv2.weight', 'vistr.backbone.0.body.layer3.2.bn2.weight', 'vistr.backbone.0.body.layer3.2.bn2.bias', 'vistr.backbone.0.body.layer3.2.bn2.running_mean', 'vistr.backbone.0.body.layer3.2.bn2.running_var', 'vistr.backbone.0.body.layer3.2.conv3.weight', 'vistr.backbone.0.body.layer3.2.bn3.weight', 'vistr.backbone.0.body.layer3.2.bn3.bias', 'vistr.backbone.0.body.layer3.2.bn3.running_mean', 'vistr.backbone.0.body.layer3.2.bn3.running_var', 'vistr.backbone.0.body.layer3.3.conv1.weight', 'vistr.backbone.0.body.layer3.3.bn1.weight', 'vistr.backbone.0.body.layer3.3.bn1.bias', 'vistr.backbone.0.body.layer3.3.bn1.running_mean', 'vistr.backbone.0.body.layer3.3.bn1.running_var', 'vistr.backbone.0.body.layer3.3.conv2.weight', 'vistr.backbone.0.body.layer3.3.bn2.weight', 'vistr.backbone.0.body.layer3.3.bn2.bias', 'vistr.backbone.0.body.layer3.3.bn2.running_mean', 'vistr.backbone.0.body.layer3.3.bn2.running_var', 'vistr.backbone.0.body.layer3.3.conv3.weight', 'vistr.backbone.0.body.layer3.3.bn3.weight', 'vistr.backbone.0.body.layer3.3.bn3.bias', 'vistr.backbone.0.body.layer3.3.bn3.running_mean', 'vistr.backbone.0.body.layer3.3.bn3.running_var', 'vistr.backbone.0.body.layer3.4.conv1.weight', 'vistr.backbone.0.body.layer3.4.bn1.weight', 'vistr.backbone.0.body.layer3.4.bn1.bias', 'vistr.backbone.0.body.layer3.4.bn1.running_mean', 'vistr.backbone.0.body.layer3.4.bn1.running_var', 'vistr.backbone.0.body.layer3.4.conv2.weight', 'vistr.backbone.0.body.layer3.4.bn2.weight', 'vistr.backbone.0.body.layer3.4.bn2.bias', 'vistr.backbone.0.body.layer3.4.bn2.running_mean', 'vistr.backbone.0.body.layer3.4.bn2.running_var', 'vistr.backbone.0.body.layer3.4.conv3.weight', 'vistr.backbone.0.body.layer3.4.bn3.weight', 'vistr.backbone.0.body.layer3.4.bn3.bias', 'vistr.backbone.0.body.layer3.4.bn3.running_mean', 'vistr.backbone.0.body.layer3.4.bn3.running_var', 'vistr.backbone.0.body.layer3.5.conv1.weight', 'vistr.backbone.0.body.layer3.5.bn1.weight', 'vistr.backbone.0.body.layer3.5.bn1.bias', 'vistr.backbone.0.body.layer3.5.bn1.running_mean', 'vistr.backbone.0.body.layer3.5.bn1.running_var', 'vistr.backbone.0.body.layer3.5.conv2.weight', 'vistr.backbone.0.body.layer3.5.bn2.weight', 'vistr.backbone.0.body.layer3.5.bn2.bias', 'vistr.backbone.0.body.layer3.5.bn2.running_mean', 'vistr.backbone.0.body.layer3.5.bn2.running_var', 'vistr.backbone.0.body.layer3.5.conv3.weight', 'vistr.backbone.0.body.layer3.5.bn3.weight', 'vistr.backbone.0.body.layer3.5.bn3.bias', 'vistr.backbone.0.body.layer3.5.bn3.running_mean', 'vistr.backbone.0.body.layer3.5.bn3.running_var', 'vistr.backbone.0.body.layer3.6.conv1.weight', 'vistr.backbone.0.body.layer3.6.bn1.weight', 'vistr.backbone.0.body.layer3.6.bn1.bias', 'vistr.backbone.0.body.layer3.6.bn1.running_mean', 'vistr.backbone.0.body.layer3.6.bn1.running_var', 'vistr.backbone.0.body.layer3.6.conv2.weight', 'vistr.backbone.0.body.layer3.6.bn2.weight', 'vistr.backbone.0.body.layer3.6.bn2.bias', 'vistr.backbone.0.body.layer3.6.bn2.running_mean', 'vistr.backbone.0.body.layer3.6.bn2.running_var', 'vistr.backbone.0.body.layer3.6.conv3.weight', 'vistr.backbone.0.body.layer3.6.bn3.weight', 'vistr.backbone.0.body.layer3.6.bn3.bias', 'vistr.backbone.0.body.layer3.6.bn3.running_mean', 'vistr.backbone.0.body.layer3.6.bn3.running_var', 'vistr.backbone.0.body.layer3.7.conv1.weight', 'vistr.backbone.0.body.layer3.7.bn1.weight', 'vistr.backbone.0.body.layer3.7.bn1.bias', 'vistr.backbone.0.body.layer3.7.bn1.running_mean', 'vistr.backbone.0.body.layer3.7.bn1.running_var', 'vistr.backbone.0.body.layer3.7.conv2.weight', 'vistr.backbone.0.body.layer3.7.bn2.weight', 'vistr.backbone.0.body.layer3.7.bn2.bias', 'vistr.backbone.0.body.layer3.7.bn2.running_mean', 'vistr.backbone.0.body.layer3.7.bn2.running_var', 'vistr.backbone.0.body.layer3.7.conv3.weight', 'vistr.backbone.0.body.layer3.7.bn3.weight', 'vistr.backbone.0.body.layer3.7.bn3.bias', 'vistr.backbone.0.body.layer3.7.bn3.running_mean', 'vistr.backbone.0.body.layer3.7.bn3.running_var', 'vistr.backbone.0.body.layer3.8.conv1.weight', 'vistr.backbone.0.body.layer3.8.bn1.weight', 'vistr.backbone.0.body.layer3.8.bn1.bias', 'vistr.backbone.0.body.layer3.8.bn1.running_mean', 'vistr.backbone.0.body.layer3.8.bn1.running_var', 'vistr.backbone.0.body.layer3.8.conv2.weight', 'vistr.backbone.0.body.layer3.8.bn2.weight', 'vistr.backbone.0.body.layer3.8.bn2.bias', 'vistr.backbone.0.body.layer3.8.bn2.running_mean', 'vistr.backbone.0.body.layer3.8.bn2.running_var', 'vistr.backbone.0.body.layer3.8.conv3.weight', 'vistr.backbone.0.body.layer3.8.bn3.weight', 'vistr.backbone.0.body.layer3.8.bn3.bias', 'vistr.backbone.0.body.layer3.8.bn3.running_mean', 'vistr.backbone.0.body.layer3.8.bn3.running_var', 'vistr.backbone.0.body.layer3.9.conv1.weight', 'vistr.backbone.0.body.layer3.9.bn1.weight', 'vistr.backbone.0.body.layer3.9.bn1.bias', 'vistr.backbone.0.body.layer3.9.bn1.running_mean', 'vistr.backbone.0.body.layer3.9.bn1.running_var', 'vistr.backbone.0.body.layer3.9.conv2.weight', 'vistr.backbone.0.body.layer3.9.bn2.weight', 'vistr.backbone.0.body.layer3.9.bn2.bias', 'vistr.backbone.0.body.layer3.9.bn2.running_mean', 'vistr.backbone.0.body.layer3.9.bn2.running_var', 'vistr.backbone.0.body.layer3.9.conv3.weight', 'vistr.backbone.0.body.layer3.9.bn3.weight', 'vistr.backbone.0.body.layer3.9.bn3.bias', 'vistr.backbone.0.body.layer3.9.bn3.running_mean', 'vistr.backbone.0.body.layer3.9.bn3.running_var', 'vistr.backbone.0.body.layer3.10.conv1.weight', 'vistr.backbone.0.body.layer3.10.bn1.weight', 'vistr.backbone.0.body.layer3.10.bn1.bias', 'vistr.backbone.0.body.layer3.10.bn1.running_mean', 'vistr.backbone.0.body.layer3.10.bn1.running_var', 'vistr.backbone.0.body.layer3.10.conv2.weight', 'vistr.backbone.0.body.layer3.10.bn2.weight', 'vistr.backbone.0.body.layer3.10.bn2.bias', 'vistr.backbone.0.body.layer3.10.bn2.running_mean', 'vistr.backbone.0.body.layer3.10.bn2.running_var', 'vistr.backbone.0.body.layer3.10.conv3.weight', 'vistr.backbone.0.body.layer3.10.bn3.weight', 'vistr.backbone.0.body.layer3.10.bn3.bias', 'vistr.backbone.0.body.layer3.10.bn3.running_mean', 'vistr.backbone.0.body.layer3.10.bn3.running_var', 'vistr.backbone.0.body.layer3.11.conv1.weight', 'vistr.backbone.0.body.layer3.11.bn1.weight', 'vistr.backbone.0.body.layer3.11.bn1.bias', 'vistr.backbone.0.body.layer3.11.bn1.running_mean', 'vistr.backbone.0.body.layer3.11.bn1.running_var', 'vistr.backbone.0.body.layer3.11.conv2.weight', 'vistr.backbone.0.body.layer3.11.bn2.weight', 'vistr.backbone.0.body.layer3.11.bn2.bias', 'vistr.backbone.0.body.layer3.11.bn2.running_mean', 'vistr.backbone.0.body.layer3.11.bn2.running_var', 'vistr.backbone.0.body.layer3.11.conv3.weight', 'vistr.backbone.0.body.layer3.11.bn3.weight', 'vistr.backbone.0.body.layer3.11.bn3.bias', 'vistr.backbone.0.body.layer3.11.bn3.running_mean', 'vistr.backbone.0.body.layer3.11.bn3.running_var', 'vistr.backbone.0.body.layer3.12.conv1.weight', 'vistr.backbone.0.body.layer3.12.bn1.weight', 'vistr.backbone.0.body.layer3.12.bn1.bias', 'vistr.backbone.0.body.layer3.12.bn1.running_mean', 'vistr.backbone.0.body.layer3.12.bn1.running_var', 'vistr.backbone.0.body.layer3.12.conv2.weight', 'vistr.backbone.0.body.layer3.12.bn2.weight', 'vistr.backbone.0.body.layer3.12.bn2.bias', 'vistr.backbone.0.body.layer3.12.bn2.running_mean', 'vistr.backbone.0.body.layer3.12.bn2.running_var', 'vistr.backbone.0.body.layer3.12.conv3.weight', 'vistr.backbone.0.body.layer3.12.bn3.weight', 'vistr.backbone.0.body.layer3.12.bn3.bias', 'vistr.backbone.0.body.layer3.12.bn3.running_mean', 'vistr.backbone.0.body.layer3.12.bn3.running_var', 'vistr.backbone.0.body.layer3.13.conv1.weight', 'vistr.backbone.0.body.layer3.13.bn1.weight', 'vistr.backbone.0.body.layer3.13.bn1.bias', 'vistr.backbone.0.body.layer3.13.bn1.running_mean', 'vistr.backbone.0.body.layer3.13.bn1.running_var', 'vistr.backbone.0.body.layer3.13.conv2.weight', 'vistr.backbone.0.body.layer3.13.bn2.weight', 'vistr.backbone.0.body.layer3.13.bn2.bias', 'vistr.backbone.0.body.layer3.13.bn2.running_mean', 'vistr.backbone.0.body.layer3.13.bn2.running_var', 'vistr.backbone.0.body.layer3.13.conv3.weight', 'vistr.backbone.0.body.layer3.13.bn3.weight', 'vistr.backbone.0.body.layer3.13.bn3.bias', 'vistr.backbone.0.body.layer3.13.bn3.running_mean', 'vistr.backbone.0.body.layer3.13.bn3.running_var', 'vistr.backbone.0.body.layer3.14.conv1.weight', 'vistr.backbone.0.body.layer3.14.bn1.weight', 'vistr.backbone.0.body.layer3.14.bn1.bias', 'vistr.backbone.0.body.layer3.14.bn1.running_mean', 'vistr.backbone.0.body.layer3.14.bn1.running_var', 'vistr.backbone.0.body.layer3.14.conv2.weight', 'vistr.backbone.0.body.layer3.14.bn2.weight', 'vistr.backbone.0.body.layer3.14.bn2.bias', 'vistr.backbone.0.body.layer3.14.bn2.running_mean', 'vistr.backbone.0.body.layer3.14.bn2.running_var', 'vistr.backbone.0.body.layer3.14.conv3.weight', 'vistr.backbone.0.body.layer3.14.bn3.weight', 'vistr.backbone.0.body.layer3.14.bn3.bias', 'vistr.backbone.0.body.layer3.14.bn3.running_mean', 'vistr.backbone.0.body.layer3.14.bn3.running_var', 'vistr.backbone.0.body.layer3.15.conv1.weight', 'vistr.backbone.0.body.layer3.15.bn1.weight', 'vistr.backbone.0.body.layer3.15.bn1.bias', 'vistr.backbone.0.body.layer3.15.bn1.running_mean', 'vistr.backbone.0.body.layer3.15.bn1.running_var', 'vistr.backbone.0.body.layer3.15.conv2.weight', 'vistr.backbone.0.body.layer3.15.bn2.weight', 'vistr.backbone.0.body.layer3.15.bn2.bias', 'vistr.backbone.0.body.layer3.15.bn2.running_mean', 'vistr.backbone.0.body.layer3.15.bn2.running_var', 'vistr.backbone.0.body.layer3.15.conv3.weight', 'vistr.backbone.0.body.layer3.15.bn3.weight', 'vistr.backbone.0.body.layer3.15.bn3.bias', 'vistr.backbone.0.body.layer3.15.bn3.running_mean', 'vistr.backbone.0.body.layer3.15.bn3.running_var', 'vistr.backbone.0.body.layer3.16.conv1.weight', 'vistr.backbone.0.body.layer3.16.bn1.weight', 'vistr.backbone.0.body.layer3.16.bn1.bias', 'vistr.backbone.0.body.layer3.16.bn1.running_mean', 'vistr.backbone.0.body.layer3.16.bn1.running_var', 'vistr.backbone.0.body.layer3.16.conv2.weight', 'vistr.backbone.0.body.layer3.16.bn2.weight', 'vistr.backbone.0.body.layer3.16.bn2.bias', 'vistr.backbone.0.body.layer3.16.bn2.running_mean', 'vistr.backbone.0.body.layer3.16.bn2.running_var', 'vistr.backbone.0.body.layer3.16.conv3.weight', 'vistr.backbone.0.body.layer3.16.bn3.weight', 'vistr.backbone.0.body.layer3.16.bn3.bias', 'vistr.backbone.0.body.layer3.16.bn3.running_mean', 'vistr.backbone.0.body.layer3.16.bn3.running_var', 'vistr.backbone.0.body.layer3.17.conv1.weight', 'vistr.backbone.0.body.layer3.17.bn1.weight', 'vistr.backbone.0.body.layer3.17.bn1.bias', 'vistr.backbone.0.body.layer3.17.bn1.running_mean', 'vistr.backbone.0.body.layer3.17.bn1.running_var', 'vistr.backbone.0.body.layer3.17.conv2.weight', 'vistr.backbone.0.body.layer3.17.bn2.weight', 'vistr.backbone.0.body.layer3.17.bn2.bias', 'vistr.backbone.0.body.layer3.17.bn2.running_mean', 'vistr.backbone.0.body.layer3.17.bn2.running_var', 'vistr.backbone.0.body.layer3.17.conv3.weight', 'vistr.backbone.0.body.layer3.17.bn3.weight', 'vistr.backbone.0.body.layer3.17.bn3.bias', 'vistr.backbone.0.body.layer3.17.bn3.running_mean', 'vistr.backbone.0.body.layer3.17.bn3.running_var', 'vistr.backbone.0.body.layer3.18.conv1.weight', 'vistr.backbone.0.body.layer3.18.bn1.weight', 'vistr.backbone.0.body.layer3.18.bn1.bias', 'vistr.backbone.0.body.layer3.18.bn1.running_mean', 'vistr.backbone.0.body.layer3.18.bn1.running_var', 'vistr.backbone.0.body.layer3.18.conv2.weight', 'vistr.backbone.0.body.layer3.18.bn2.weight', 'vistr.backbone.0.body.layer3.18.bn2.bias', 'vistr.backbone.0.body.layer3.18.bn2.running_mean', 'vistr.backbone.0.body.layer3.18.bn2.running_var', 'vistr.backbone.0.body.layer3.18.conv3.weight', 'vistr.backbone.0.body.layer3.18.bn3.weight', 'vistr.backbone.0.body.layer3.18.bn3.bias', 'vistr.backbone.0.body.layer3.18.bn3.running_mean', 'vistr.backbone.0.body.layer3.18.bn3.running_var', 'vistr.backbone.0.body.layer3.19.conv1.weight', 'vistr.backbone.0.body.layer3.19.bn1.weight', 'vistr.backbone.0.body.layer3.19.bn1.bias', 'vistr.backbone.0.body.layer3.19.bn1.running_mean', 'vistr.backbone.0.body.layer3.19.bn1.running_var', 'vistr.backbone.0.body.layer3.19.conv2.weight', 'vistr.backbone.0.body.layer3.19.bn2.weight', 'vistr.backbone.0.body.layer3.19.bn2.bias', 'vistr.backbone.0.body.layer3.19.bn2.running_mean', 'vistr.backbone.0.body.layer3.19.bn2.running_var', 'vistr.backbone.0.body.layer3.19.conv3.weight', 'vistr.backbone.0.body.layer3.19.bn3.weight', 'vistr.backbone.0.body.layer3.19.bn3.bias', 'vistr.backbone.0.body.layer3.19.bn3.running_mean', 'vistr.backbone.0.body.layer3.19.bn3.running_var', 'vistr.backbone.0.body.layer3.20.conv1.weight', 'vistr.backbone.0.body.layer3.20.bn1.weight', 'vistr.backbone.0.body.layer3.20.bn1.bias', 'vistr.backbone.0.body.layer3.20.bn1.running_mean', 'vistr.backbone.0.body.layer3.20.bn1.running_var', 'vistr.backbone.0.body.layer3.20.conv2.weight', 'vistr.backbone.0.body.layer3.20.bn2.weight', 'vistr.backbone.0.body.layer3.20.bn2.bias', 'vistr.backbone.0.body.layer3.20.bn2.running_mean', 'vistr.backbone.0.body.layer3.20.bn2.running_var', 'vistr.backbone.0.body.layer3.20.conv3.weight', 'vistr.backbone.0.body.layer3.20.bn3.weight', 'vistr.backbone.0.body.layer3.20.bn3.bias', 'vistr.backbone.0.body.layer3.20.bn3.running_mean', 'vistr.backbone.0.body.layer3.20.bn3.running_var', 'vistr.backbone.0.body.layer3.21.conv1.weight', 'vistr.backbone.0.body.layer3.21.bn1.weight', 'vistr.backbone.0.body.layer3.21.bn1.bias', 'vistr.backbone.0.body.layer3.21.bn1.running_mean', 'vistr.backbone.0.body.layer3.21.bn1.running_var', 'vistr.backbone.0.body.layer3.21.conv2.weight', 'vistr.backbone.0.body.layer3.21.bn2.weight', 'vistr.backbone.0.body.layer3.21.bn2.bias', 'vistr.backbone.0.body.layer3.21.bn2.running_mean', 'vistr.backbone.0.body.layer3.21.bn2.running_var', 'vistr.backbone.0.body.layer3.21.conv3.weight', 'vistr.backbone.0.body.layer3.21.bn3.weight', 'vistr.backbone.0.body.layer3.21.bn3.bias', 'vistr.backbone.0.body.layer3.21.bn3.running_mean', 'vistr.backbone.0.body.layer3.21.bn3.running_var', 'vistr.backbone.0.body.layer3.22.conv1.weight', 'vistr.backbone.0.body.layer3.22.bn1.weight', 'vistr.backbone.0.body.layer3.22.bn1.bias', 'vistr.backbone.0.body.layer3.22.bn1.running_mean', 'vistr.backbone.0.body.layer3.22.bn1.running_var', 'vistr.backbone.0.body.layer3.22.conv2.weight', 'vistr.backbone.0.body.layer3.22.bn2.weight', 'vistr.backbone.0.body.layer3.22.bn2.bias', 'vistr.backbone.0.body.layer3.22.bn2.running_mean', 'vistr.backbone.0.body.layer3.22.bn2.running_var', 'vistr.backbone.0.body.layer3.22.conv3.weight', 'vistr.backbone.0.body.layer3.22.bn3.weight', 'vistr.backbone.0.body.layer3.22.bn3.bias', 'vistr.backbone.0.body.layer3.22.bn3.running_mean', 'vistr.backbone.0.body.layer3.22.bn3.running_var', 'vistr.backbone.0.body.layer4.0.conv1.weight', 'vistr.backbone.0.body.layer4.0.bn1.weight', 'vistr.backbone.0.body.layer4.0.bn1.bias', 'vistr.backbone.0.body.layer4.0.bn1.running_mean', 'vistr.backbone.0.body.layer4.0.bn1.running_var', 'vistr.backbone.0.body.layer4.0.conv2.weight', 'vistr.backbone.0.body.layer4.0.bn2.weight', 'vistr.backbone.0.body.layer4.0.bn2.bias', 'vistr.backbone.0.body.layer4.0.bn2.running_mean', 'vistr.backbone.0.body.layer4.0.bn2.running_var', 'vistr.backbone.0.body.layer4.0.conv3.weight', 'vistr.backbone.0.body.layer4.0.bn3.weight', 'vistr.backbone.0.body.layer4.0.bn3.bias', 'vistr.backbone.0.body.layer4.0.bn3.running_mean', 'vistr.backbone.0.body.layer4.0.bn3.running_var', 'vistr.backbone.0.body.layer4.0.downsample.0.weight', 'vistr.backbone.0.body.layer4.0.downsample.1.weight', 'vistr.backbone.0.body.layer4.0.downsample.1.bias', 'vistr.backbone.0.body.layer4.0.downsample.1.running_mean', 'vistr.backbone.0.body.layer4.0.downsample.1.running_var', 'vistr.backbone.0.body.layer4.1.conv1.weight', 'vistr.backbone.0.body.layer4.1.bn1.weight', 'vistr.backbone.0.body.layer4.1.bn1.bias', 'vistr.backbone.0.body.layer4.1.bn1.running_mean', 'vistr.backbone.0.body.layer4.1.bn1.running_var', 'vistr.backbone.0.body.layer4.1.conv2.weight', 'vistr.backbone.0.body.layer4.1.bn2.weight', 'vistr.backbone.0.body.layer4.1.bn2.bias', 'vistr.backbone.0.body.layer4.1.bn2.running_mean', 'vistr.backbone.0.body.layer4.1.bn2.running_var', 'vistr.backbone.0.body.layer4.1.conv3.weight', 'vistr.backbone.0.body.layer4.1.bn3.weight', 'vistr.backbone.0.body.layer4.1.bn3.bias', 'vistr.backbone.0.body.layer4.1.bn3.running_mean', 'vistr.backbone.0.body.layer4.1.bn3.running_var', 'vistr.backbone.0.body.layer4.2.conv1.weight', 'vistr.backbone.0.body.layer4.2.bn1.weight', 'vistr.backbone.0.body.layer4.2.bn1.bias', 'vistr.backbone.0.body.layer4.2.bn1.running_mean', 'vistr.backbone.0.body.layer4.2.bn1.running_var', 'vistr.backbone.0.body.layer4.2.conv2.weight', 'vistr.backbone.0.body.layer4.2.bn2.weight', 'vistr.backbone.0.body.layer4.2.bn2.bias', 'vistr.backbone.0.body.layer4.2.bn2.running_mean', 'vistr.backbone.0.body.layer4.2.bn2.running_var', 'vistr.backbone.0.body.layer4.2.conv3.weight', 'vistr.backbone.0.body.layer4.2.bn3.weight', 'vistr.backbone.0.body.layer4.2.bn3.bias', 'vistr.backbone.0.body.layer4.2.bn3.running_mean', 'vistr.backbone.0.body.layer4.2.bn3.running_var', 'bbox_attention.q_linear.weight', 'bbox_attention.q_linear.bias', 'bbox_attention.k_linear.weight', 'bbox_attention.k_linear.bias', 'mask_head.lay1.weight', 'mask_head.lay1.bias', 'mask_head.gn1.weight', 'mask_head.gn1.bias', 'mask_head.lay2.weight', 'mask_head.lay2.bias', 'mask_head.gn2.weight', 'mask_head.gn2.bias', 'mask_head.lay3.weight', 'mask_head.lay3.bias', 'mask_head.gn3.weight', 'mask_head.gn3.bias', 'mask_head.lay4.weight', 'mask_head.lay4.bias', 'mask_head.gn4.weight', 'mask_head.gn4.bias', 'mask_head.gn5.weight', 'mask_head.gn5.bias', 'mask_head.conv_offset.weight', 'mask_head.conv_offset.bias', 'mask_head.dcn.weight', 'mask_head.adapter1.weight', 'mask_head.adapter1.bias', 'mask_head.adapter2.weight', 'mask_head.adapter2.bias', 'mask_head.adapter3.weight', 'mask_head.adapter3.bias', 'insmask_head.0.weight', 'insmask_head.0.bias', 'insmask_head.1.weight', 'insmask_head.1.bias', 'insmask_head.3.weight', 'insmask_head.3.bias', 'insmask_head.4.weight', 'insmask_head.4.bias', 'insmask_head.6.weight', 'insmask_head.6.bias', 'insmask_head.7.weight', 'insmask_head.7.bias', 'insmask_head.9.weight', 'insmask_head.9.bias'])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5e1ad989",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args.labels_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdba3622",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load coco pretrained weight\n",
    "checkpoint = torch.load(args.pretrained_weights, map_location='cpu')['model']\n",
    "del checkpoint[\"vistr.class_embed.weight\"]\n",
    "del checkpoint[\"vistr.class_embed.bias\"]\n",
    "del checkpoint[\"vistr.query_embed.weight\"]\n",
    "model.load_state_dict(checkpoint,strict=False)\n",
    "\n",
    "args.resume = False\n",
    "# if args.resume:\n",
    "#     if args.resume.startswith('https'):\n",
    "#         checkpoint = torch.hub.load_state_dict_from_url(\n",
    "#             args.resume, map_location='cpu', check_hash=True)\n",
    "#     else:\n",
    "#         checkpoint = torch.load(args.resume, map_location='cpu')\n",
    "#     model_without_ddp.load_state_dict(checkpoint['model'])\n",
    "#     if not args.eval and 'optimizer' in checkpoint and 'lr_scheduler' in checkpoint and 'epoch' in checkpoint:\n",
    "#         optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "#         lr_scheduler.load_state_dict(checkpoint['lr_scheduler'])\n",
    "#         args.start_epoch = checkpoint['epoch'] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba6dace",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# no validation ground truth for ytvos dataset\n",
    "dataset_train = ImagePathDataset(train_image_list, train_mask_list,\n",
    "                                 n_frames, transform=make_transform(image_set='train'))\n",
    "if args.distributed:\n",
    "    sampler_train = DistributedSampler(dataset_train)\n",
    "else:\n",
    "    sampler_train = torch.utils.data.RandomSampler(dataset_train)\n",
    "\n",
    "batch_sampler_train = torch.utils.data.BatchSampler(\n",
    "    sampler_train, args.batch_size, drop_last=True)\n",
    "\n",
    "data_loader_train = DataLoader(dataset_train, batch_sampler=batch_sampler_train,\n",
    "                               collate_fn=utils.collate_fn, num_workers=args.num_workers)\n",
    "\n",
    "output_dir = Path(args.output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d4c6a4c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Start training\")\n",
    "start_time = time.time()\n",
    "for epoch in range(args.start_epoch, args.epochs):\n",
    "    if args.distributed:\n",
    "        sampler_train.set_epoch(epoch)\n",
    "    train_stats = train_one_epoch(\n",
    "        model, criterion, data_loader_train, optimizer, device, epoch,\n",
    "        args.clip_max_norm)\n",
    "    lr_scheduler.step()\n",
    "    if args.output_dir:\n",
    "        checkpoint_paths = [output_dir / 'checkpoint.pth']\n",
    "        # extra checkpoint before LR drop and every epochs\n",
    "        if (epoch + 1) % args.lr_drop == 0 or (epoch + 1) % 1 == 0:\n",
    "            checkpoint_paths.append(output_dir / f'checkpoint{epoch:04}.pth')\n",
    "        for checkpoint_path in checkpoint_paths:\n",
    "            utils.save_on_master({\n",
    "                'model': model_without_ddp.state_dict(),\n",
    "                'optimizer': optimizer.state_dict(),\n",
    "                'lr_scheduler': lr_scheduler.state_dict(),\n",
    "                'epoch': epoch,\n",
    "                'args': args,\n",
    "            }, checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0239d196",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
