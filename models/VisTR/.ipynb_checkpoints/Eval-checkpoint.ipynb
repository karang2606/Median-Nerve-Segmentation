{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c30b4d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import datetime\n",
    "import json\n",
    "import random\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, DistributedSampler\n",
    "\n",
    "import datasets\n",
    "import util.misc as utils\n",
    "from datasets import build_dataset, get_coco_api_from_dataset\n",
    "from engine import evaluate, train_one_epoch\n",
    "from models import build_model\n",
    "import torchvision.transforms as T\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from PIL import Image\n",
    "import math\n",
    "import torch.nn.functional as F\n",
    "import json\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "import pycocotools.mask as mask_util\n",
    "import re\n",
    "import glob\n",
    "from tqdm.notebook import tqdm\n",
    "import cv2\n",
    "import pycocotools.mask as mask_utils\n",
    "from torchvision.ops import masks_to_boxes\n",
    "import torch.distributions as dist\n",
    "\n",
    "from mmcv.cnn.utils.flops_counter import add_flops_counting_methods, flops_to_string, params_to_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff619311",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AddGaussianNoise(object):\n",
    "    def __init__(self, mean=0., std=1.):\n",
    "        self.std = std\n",
    "        self.mean = mean\n",
    "        \n",
    "    def __call__(self, tensor):\n",
    "        return tensor + torch.randn(tensor.size()) * self.std + self.mean\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + '(mean={0}, std={1})'.format(self.mean, self.std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0fe8287",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AddPoissonNoise(object):\n",
    "    def __init__(self, intensity=0.5):\n",
    "        self.intensity = intensity\n",
    "        \n",
    "    def __call__(self, tensor):\n",
    "        \n",
    "        # Create a Poisson distribution with the specified intensity\n",
    "        poisson = dist.Poisson(self.intensity)\n",
    "\n",
    "        # Generate random noise with the same size as the image\n",
    "        noise = poisson.sample(tensor.size())\n",
    "\n",
    "        # Add the noise to the image\n",
    "        noisy_image = tensor + noise\n",
    "\n",
    "        # Clip the image to ensure pixel values are within the valid range\n",
    "        noisy_image = torch.clamp(noisy_image, 0, 1)\n",
    "\n",
    "        # Convert the noisy image back to the original data type\n",
    "        noisy_image = noisy_image.type(tensor.dtype)\n",
    "\n",
    "        return noisy_image\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + '(intensity={0})'.format(self.intensity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "746ae8ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_args_parser():\n",
    "    \n",
    "    parser = argparse.ArgumentParser('Set transformer detector', add_help=False)\n",
    "    parser.add_argument('--lr', default=1e-4, type=float)\n",
    "    parser.add_argument('--lr_backbone', default=1e-5, type=float)\n",
    "    parser.add_argument('--batch_size', default=2, type=int)\n",
    "    parser.add_argument('--weight_decay', default=1e-4, type=float)\n",
    "    parser.add_argument('--epochs', default=150, type=int)\n",
    "    parser.add_argument('--lr_drop', default=100, type=int)\n",
    "    parser.add_argument('--clip_max_norm', default=0.1, type=float,\n",
    "                        help='gradient clipping max norm')\n",
    "\n",
    "    # Model parameters\n",
    "    parser.add_argument('--model_path', type=str, default=None,\n",
    "                        help=\"Path to the model weights.\")\n",
    "    # * Backbone\n",
    "    parser.add_argument('--backbone', default='resnet101', type=str,\n",
    "                        help=\"Name of the convolutional backbone to use\")\n",
    "    parser.add_argument('--dilation', action='store_true',\n",
    "                        help=\"If true, we replace stride with dilation in the last convolutional block (DC5)\")\n",
    "    parser.add_argument('--position_embedding', default='sine', type=str, choices=('sine', 'learned'),\n",
    "                        help=\"Type of positional embedding to use on top of the image features\")\n",
    "\n",
    "    # * Transformer\n",
    "    parser.add_argument('--enc_layers', default=6, type=int,\n",
    "                        help=\"Number of encoding layers in the transformer\")\n",
    "    parser.add_argument('--dec_layers', default=6, type=int,\n",
    "                        help=\"Number of decoding layers in the transformer\")\n",
    "    parser.add_argument('--dim_feedforward', default=2048, type=int,\n",
    "                        help=\"Intermediate size of the feedforward layers in the transformer blocks\")\n",
    "    parser.add_argument('--hidden_dim', default=384, type=int,\n",
    "                        help=\"Size of the embeddings (dimension of the transformer)\")\n",
    "    parser.add_argument('--dropout', default=0.1, type=float,\n",
    "                        help=\"Dropout applied in the transformer\")\n",
    "    parser.add_argument('--nheads', default=8, type=int,\n",
    "                        help=\"Number of attention heads inside the transformer's attentions\")\n",
    "    parser.add_argument('--num_frames', default=36, type=int,\n",
    "                        help=\"Number of frames\")\n",
    "    parser.add_argument('--num_ins', default=1, type=int,\n",
    "                        help=\"Number of instances\")\n",
    "    parser.add_argument('--num_queries', default=36, type=int,\n",
    "                        help=\"Number of query slots\")\n",
    "    parser.add_argument('--pre_norm', action='store_true')\n",
    "\n",
    "    # * Segmentation\n",
    "    parser.add_argument('--masks', action='store_true',\n",
    "                        help=\"Train segmentation head if the flag is provided\")\n",
    "\n",
    "    # Loss\n",
    "    parser.add_argument('--no_aux_loss', dest='aux_loss', action='store_false',\n",
    "                        help=\"Disables auxiliary decoding losses (loss at each layer)\")\n",
    "    parser.add_argument('--no_labels_loss', dest='labels_loss', action='store_false',\n",
    "                        help=\"Enables labels losses\")\n",
    "    parser.add_argument('--no_boxes_loss', dest='boxes_loss', action='store_false',\n",
    "                        help=\"Enables bounding box losses\")\n",
    "    parser.add_argument('--no_L1_loss', dest='L1_loss', action='store_false',\n",
    "                        help=\"Enables L1 losses for bboxes\")\n",
    "    parser.add_argument('--no_giou_loss', dest='giou_loss', action='store_false',\n",
    "                        help=\"Enables Generalized IOU losses for bboxes\")\n",
    "    parser.add_argument('--no_focal_loss', dest='focal_loss', action='store_false',\n",
    "                        help=\"Enables Focal losses for mask\")\n",
    "    parser.add_argument('--no_dice_loss', dest='dice_loss', action='store_false',\n",
    "                        help=\"Enables dice losses for mask\")\n",
    "    \n",
    "    # * Matcher\n",
    "    parser.add_argument('--set_cost_class', default=1, type=float,\n",
    "                        help=\"Class coefficient in the matching cost\")\n",
    "    parser.add_argument('--set_cost_bbox', default=5, type=float,\n",
    "                        help=\"L1 box coefficient in the matching cost\")\n",
    "    parser.add_argument('--set_cost_giou', default=2, type=float,\n",
    "                        help=\"giou box coefficient in the matching cost\")\n",
    "    # * Loss coefficients\n",
    "    parser.add_argument('--mask_loss_coef', default=1, type=float)\n",
    "    parser.add_argument('--dice_loss_coef', default=1, type=float)\n",
    "    parser.add_argument('--bbox_loss_coef', default=5, type=float)\n",
    "    parser.add_argument('--giou_loss_coef', default=2, type=float)\n",
    "    parser.add_argument('--eos_coef', default=0.1, type=float,\n",
    "                        help=\"Relative classification weight of the no-object class\")\n",
    "\n",
    "    # dataset parameters\n",
    "    parser.add_argument('--img_path', default='data/ytvos/valid/JPEGImages/')\n",
    "    parser.add_argument('--ann_path', default='data/ytvos/annotations/instances_val_sub.json')\n",
    "    parser.add_argument('--save_path', default='results.json')\n",
    "    parser.add_argument('--dataset_file', default='ytvos')\n",
    "    parser.add_argument('--coco_path', type=str)\n",
    "    parser.add_argument('--coco_panoptic_path', type=str)\n",
    "    parser.add_argument('--remove_difficult', action='store_true')\n",
    "\n",
    "    parser.add_argument('--output_dir', default='output_ytvos',\n",
    "                        help='path where to save, empty for no saving')\n",
    "    parser.add_argument('--device', default='cuda',\n",
    "                        help='device to use for training / testing')\n",
    "    parser.add_argument('--seed', default=42, type=int)\n",
    "    parser.add_argument('--resume', default='', help='resume from checkpoint')\n",
    "    parser.add_argument('--start_epoch', default=0, type=int, metavar='N',\n",
    "                        help='start epoch')\n",
    "    #parser.add_argument('--eval', action='store_true')\n",
    "    parser.add_argument('--eval', action='store_false')\n",
    "    parser.add_argument('--num_workers', default=0, type=int)\n",
    "\n",
    "    # distributed training parameters\n",
    "    parser.add_argument('--world_size', default=1, type=int,\n",
    "                        help='number of distributed processes')\n",
    "    parser.add_argument('--dist_url', default='env://', help='url used to set up distributed training')\n",
    "    return parser\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd60b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for output bounding box post-processing\n",
    "def box_cxcywh_to_xyxy(x):\n",
    "    x_c, y_c, w, h = x.unbind(1)\n",
    "    b = [(x_c - 0.5 * w), (y_c - 0.5 * h),\n",
    "         (x_c + 0.5 * w), (y_c + 0.5 * h)]\n",
    "    return torch.stack(b, dim=1)\n",
    "\n",
    "def rescale_bboxes(out_bbox, size):\n",
    "    img_w, img_h = size\n",
    "    b = box_cxcywh_to_xyxy(out_bbox)\n",
    "    b = b.cpu() * torch.tensor([img_w, img_h, img_w, img_h], dtype=torch.float32)\n",
    "    return b\n",
    "\n",
    "def get_bbox(mask_list):\n",
    "    return torch.cat([masks_to_boxes(mask) for mask in mask_list], dim=0)\n",
    "\n",
    "pat=re.compile(\"(\\d+)\\D*$\")\n",
    "\n",
    "def key_func(x):\n",
    "    mat=pat.search(os.path.split(x)[-1]) # match last group of digits\n",
    "    if mat is None:\n",
    "        return x\n",
    "    return \"{:>10}\".format(mat.group(1)) # right align to 10 digits\n",
    "\n",
    "def get_metric(pred, truth):\n",
    "    # Sensitivity == Recall\n",
    "    SE = PC = F1 = DC = 0\n",
    "    \n",
    "    # SR : Segmentation Result\n",
    "    # GT : Ground Truth\n",
    "    SR, GT = pred, truth\n",
    "\n",
    "    # TP : True Positive\n",
    "    TP = ((SR==1)&(GT==1)).sum().item()\n",
    "\n",
    "    # FN : False Negative\n",
    "    FN = ((SR==0)&(GT==1)).sum().item()\n",
    "\n",
    "    # FP : False Positive\n",
    "    FP = ((SR==1)&(GT==0)).sum().item()\n",
    "\n",
    "    Inter = TP\n",
    "    Union = SR.sum().item() + GT.sum().item()\n",
    "    SE = float(TP)/(float(TP+FN) + 1e-6) #Recall\n",
    "    PC = float(TP)/(float(TP+FP) + 1e-6) #Precision\n",
    "    F1 = 2*SE*PC/(SE+PC + 1e-6) #F1 Score\n",
    "    DC = float(2*Inter)/(float(Union) + 1e-6) #Dice Score\n",
    "\n",
    "    return np.array([SE, PC, F1, DC])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5959d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pred_video(img, msk, type_ = None):\n",
    "    if not isinstance(img, np.ndarray): img = np.array(img)\n",
    "    if not isinstance(msk, np.ndarray): msk = np.array(msk)\n",
    "    if img.dtype!='uint8': img= (img*255).astype(np.uint8)\n",
    "    if msk.dtype!='uint8': msk= (msk*255).astype(np.uint8)\n",
    "    if(len(img.shape)<3): img = cv2.cvtColor(img,cv2.COLOR_GRAY2RGB)\n",
    "    \n",
    "    cnts = cv2.findContours(msk, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cnts = cnts[0] if len(cnts) == 2 else cnts[1]\n",
    "    if type_ == 'GT':\n",
    "        for c in cnts:\n",
    "            cv2.drawContours(img, [c], -1, (0, 255, 0), thickness=2)\n",
    "    if type_ == 'Pred':\n",
    "        for c in cnts:\n",
    "            cv2.drawContours(img, [c], -1, (0, 0, 255), thickness=2)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac39139",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser('VisTR Inference script',\n",
    "                                 parents=[get_args_parser()])\n",
    "args = parser.parse_args(\"\")\n",
    "args.num_classes = 41\n",
    "\n",
    "if args.output_dir:\n",
    "    Path(args.output_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "args.masks = True\n",
    "args.device = 'cuda:0'\n",
    "\n",
    "#change these to 1 & 36\n",
    "args.num_ins = 1\n",
    "args.num_queries = 36\n",
    "args.num_frames = 36\n",
    "\n",
    "device = torch.device(args.device)\n",
    "# fix the seed for reproducibility\n",
    "seed = args.seed + utils.get_rank()\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e04816",
   "metadata": {},
   "outputs": [],
   "source": [
    "args.model_path = 'r101_vistr/checkpoint0003.pth'\n",
    "\n",
    "with torch.no_grad():\n",
    "    model, criterion, postprocessors = build_model(args)\n",
    "    state_dict = torch.load(args.model_path,  map_location='cpu')['model']\n",
    "    model.load_state_dict(state_dict)\n",
    "    model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c25774f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_file_dir = sorted(glob.glob('../Thesis/aster_updated_data_22_01_2022/Test/*'))\n",
    "test_file_dir\n",
    "\n",
    "test_img_path = []\n",
    "test_msk_path = []\n",
    "\n",
    "num_frames = args.num_frames\n",
    "num_ins = args.num_ins\n",
    "\n",
    "for path in test_file_dir:\n",
    "    test_img_path.append(sorted(glob.glob(path+'/*_0001_IMAGES/images/*.jpg'), key=key_func))\n",
    "    test_msk_path.append(sorted(glob.glob(path+'/*_0001_IMAGES/masks/*.png'), key=key_func))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90547630",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with torch.no_grad():\n",
    "#     model, criterion, postprocessors = build_model(args)\n",
    "#     state_dict = torch.load(args.model_path,  map_location='cpu')['model']\n",
    "#     model.load_state_dict(state_dict)\n",
    "#     model.to(device)\n",
    "    \n",
    "# n_parameters = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "# print('number of params:', n_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3677ecaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pred(model, image):\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        return model(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0700af88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(img_path, num, model, n_frames = args.num_frames):\n",
    "    \n",
    "#     model = add_flops_counting_methods(model)\n",
    "    vid = img_path[num]\n",
    "    vid_length = len(vid)\n",
    "#     vid_length = 40\n",
    "\n",
    "    pred_masks_seq_2 = []\n",
    "    pred_score_2 = []\n",
    "\n",
    "    im = Image.open(img_path[0][0])\n",
    "\n",
    "#     for i in tqdm(range(0, 40 ,n_frames), desc = 'Testing', leave = False):\n",
    "    for i in tqdm(range(0, vid_length ,n_frames), desc = 'Testing', leave = False):\n",
    "        start = i\n",
    "        end = min(i+n_frames,vid_length)\n",
    "        image = [transform(Image.open(frame)) for frame in vid[start:end]]\n",
    "#         print(image[0].size())\n",
    "        if image[0].size()[0] != 3:\n",
    "            image = [img.repeat(3,1,1).unsqueeze(0).to(device) for img in image]\n",
    "        else:\n",
    "            image = [img.unsqueeze(0).to(device) for img in image]\n",
    "        image = torch.cat(image,dim=0)\n",
    "        clip_len = end - start\n",
    "        if clip_len < n_frames:\n",
    "            image = torch.cat([image for _ in range(math.ceil(n_frames/clip_len))],dim=0)\n",
    "            image = image[:n_frames]\n",
    "#         model.start_flops_count()\n",
    "#         start = time.time()\n",
    "        outputs = get_pred(model, image)\n",
    "#         end = time.time()\n",
    "#         tim.append(len(imgs)/(end-start))\n",
    "#         AVG_flops, params_count = model.compute_average_flops_cost()\n",
    "#         print('Average flops',flops_to_string(AVG_flops))\n",
    "#         print('Parameters',params_to_string(params_count))\n",
    "#         model.stop_flops_count()\n",
    "        # end of model inference\n",
    "        logits, boxes, masks = outputs['pred_logits'].softmax(-1)[0,:,:-1], outputs['pred_boxes'][0], outputs['pred_masks'][0]\n",
    "        pred_masks = F.interpolate(masks.reshape(n_frames,num_ins,masks.shape[-2],masks.shape[-1]),(im.size[1],im.size[0]),mode=\"bilinear\").sigmoid().cpu().detach().numpy()>0.5\n",
    "        pred_logits = logits.reshape(n_frames,num_ins,logits.shape[-1]).cpu().detach().numpy()\n",
    "        pred_masks = pred_masks[:clip_len]\n",
    "        pred_logits = pred_logits[:clip_len]\n",
    "        pred_scores = np.max(pred_logits,axis=-1)\n",
    "        pred_logits = np.argmax(pred_logits,axis=-1)\n",
    "        temp = []\n",
    "        for m in range(num_ins):\n",
    "            if pred_masks[:,m].max()==0:\n",
    "                continue\n",
    "            score = pred_scores[:,m].mean()\n",
    "            #category_id = pred_logits[:,m][pred_scores[:,m].argmax()]\n",
    "            category_id = np.argmax(np.bincount(pred_logits[:,m]))\n",
    "            instance = {'score':float(score), 'category_id':int(category_id)}\n",
    "            temp.append(instance)\n",
    "        pred_score_2.append(temp)\n",
    "        pred_masks_seq_2.append(pred_masks)\n",
    "    pred_final_2 = [img[0] for batch in pred_masks_seq_2 for img in batch]\n",
    "    return pred_final_2, vid_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda70c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# threshold\n",
    "def get_bbox(gray):\n",
    "    \n",
    "    bbox=[]\n",
    "    if not isinstance(gray, np.ndarray): gray = np.array(gray)\n",
    "    if gray.dtype!='uint8': gray= (gray*255).astype(np.uint8)\n",
    "        \n",
    "#     img = cv2.cvtColor(gray,cv2.COLOR_GRAY2RGB)\n",
    "    thresh = cv2.threshold(gray,128,255,cv2.THRESH_BINARY)[1]\n",
    "\n",
    "    # get contours\n",
    "#     result = img.copy()\n",
    "    contours = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    contours = contours[0] if len(contours) == 2 else contours[1]\n",
    "    for cntr in contours:\n",
    "        x,y,w,h = cv2.boundingRect(cntr)\n",
    "        bbox.append([x,y,w,h])\n",
    "#         cv2.rectangle(result, (x, y), (x+w, y+h), (0, 0, 255), 2)\n",
    "#         print(\"x,y,w,h:\",x,y,w,h)\n",
    "    return bbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f46bfb54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_filtered_mask(mask_clip):\n",
    "    bbox =[None]*len(mask_clip)\n",
    "    cntr = [None]*len(mask_clip)\n",
    "    area = [None]*len(mask_clip)\n",
    "    filtered_mask = []\n",
    "    for i in range(len(mask_clip)):\n",
    "        frame = mask_clip[i].astype('int')\n",
    "        temp = np.zeros_like(frame)\n",
    "\n",
    "        blist = get_bbox(frame)\n",
    "\n",
    "        if len(blist) == 0:\n",
    "            temp = filtered_mask[-1]\n",
    "        elif len(blist) == 1:\n",
    "            x,y,w,h = blist[0]\n",
    "            cntr[i] = (x+w/2, y+h/2)\n",
    "            bbox[i] = (x,y,w,h)\n",
    "    #         area[i] = frame[x:x+w, y:y+h]\n",
    "            temp = frame\n",
    "        elif len(blist) > 1:\n",
    "            all_cntrs=[(x+w/2, y+h/2) for x,y,w,h in blist]\n",
    "            area = [w*h for x,y,w,h in blist]\n",
    "            if cntr[i-1] == None:\n",
    "                index = np.argmax(area)\n",
    "                cntr[i] = all_cntrs[index]\n",
    "                bbox[i] = blist[index]\n",
    "                x,y,w,h = blist[index]\n",
    "                temp[y:y+h ,x:x+w] = frame[y:y+h ,x:x+w]\n",
    "            else:\n",
    "                x0, y0 = cntr[i-1]\n",
    "                index = np.argmin([np.sqrt((x0-x)**2 + (y0-y)**2) for x,y in all_cntrs])\n",
    "                cntr[i] = all_cntrs[index]\n",
    "                bbox[i] = blist[index]\n",
    "                x,y,w,h = blist[index]\n",
    "                temp[y:y+h ,x:x+w] = frame[y:y+h ,x:x+w]\n",
    "        filtered_mask.append(temp)\n",
    "        \n",
    "    return filtered_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7d5aaa3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# weights_path = sorted(glob.glob(\"r101_vistr/no_dice_loss/*.pth\"))[1:]\n",
    "# # weights_path = sorted(glob.glob(\"r101_vistr/no_giou_loss/*.pth\"))[1:]\n",
    "# # args.giou_loss = False\n",
    "\n",
    "# # weights_path = sorted(glob.glob(\"r101_vistr/no_focal_loss/*.pth\"))[1:]\n",
    "# # args.focal_loss = False\n",
    "\n",
    "# # weights_path = sorted(glob.glob(\"r101_vistr/no_L1_loss/*.pth\"))[1:]\n",
    "# # args.L1_loss = False\n",
    "\n",
    "# # weights_path = sorted(glob.glob(\"r101_vistr/no_L1_loss/*.pth\"))[1:]\n",
    "# # args.L1_loss = False\n",
    "\n",
    "# for path in weights_path:\n",
    "#     args.model_path = path\n",
    "    \n",
    "#     with torch.no_grad():\n",
    "#         model, criterion, postprocessors = build_model(args)\n",
    "#         state_dict = torch.load(args.model_path,  map_location='cpu')['model']\n",
    "#         model.load_state_dict(state_dict)\n",
    "#         model.to(device)\n",
    "        \n",
    "#     transform = T.Compose([\n",
    "#     T.ToTensor(),\n",
    "#     T.Normalize([0.2316], [0.2038]), #mean #standard deviation\n",
    "# #     AddGaussianNoise(mean=0., std=std)\n",
    "#     ])\n",
    "#     test_res = []\n",
    "#     pred_mask = []\n",
    "    \n",
    "#     for num in tqdm(range(len(test_img_path)), leave = False):\n",
    "#     #     start = time.time()\n",
    "#         output, vid_length = test_model(test_img_path, num, model, num_frames)\n",
    "#     #     end = time.time()\n",
    "#     #     print(vid_length/(end-start))\n",
    "#         pred_mask.append(output)\n",
    "#     #     print(len(output))\n",
    "#         res_2 = []\n",
    "\n",
    "#         for j in range(vid_length):\n",
    "#             GT = np.array(Image.open(test_msk_path[num][j]))/255\n",
    "#             SR = output[j]\n",
    "\n",
    "#             res_2.append(get_metric(SR, GT))\n",
    "#         res_2 = np.array(res_2)\n",
    "#         test_res.append(res_2.mean(0))\n",
    "    \n",
    "#     print(f'{path}:',np.mean(test_res, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a111190b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n_parameters = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print('number of params:', n_parameters)\n",
    "\n",
    "intensities = [0, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3, 0.35, 0.4, 0.45, 0.5]\n",
    "multiple_run = []\n",
    "for _ in range(10):\n",
    "    print(_)\n",
    "    res_on_std = []\n",
    "    for intensity in intensities:\n",
    "        transform = T.Compose([\n",
    "            T.ToTensor(),\n",
    "            AddPoissonNoise(intensity=intensity),\n",
    "            T.Normalize([0.2316], [0.2038]), #mean #standard deviation\n",
    "#             AddGaussianNoise(mean=0., std=std)\n",
    "        ])\n",
    "\n",
    "        test_res = []\n",
    "        pred_mask = []\n",
    "        for num in tqdm(range(len(test_img_path)), leave = False):\n",
    "        #     start = time.time()\n",
    "            output, vid_length = test_model(test_img_path, num, model, num_frames)\n",
    "        #     end = time.time()\n",
    "        #     print(vid_length/(end-start))\n",
    "            pred_mask.append(output)\n",
    "        #     print(len(output))\n",
    "            res_2 = []\n",
    "\n",
    "#             for j in range(40):\n",
    "            for j in range(vid_length):\n",
    "                GT = np.array(Image.open(test_msk_path[num][j]))/255\n",
    "                SR = output[j]\n",
    "\n",
    "                res_2.append(get_metric(SR, GT))\n",
    "            res_2 = np.array(res_2)\n",
    "    #         print(f'{num+1}:',res_2.mean(axis=0))\n",
    "            test_res.append(res_2)\n",
    "        mean_metric = np.mean([i.mean(axis=0) for i in test_res], axis=0)\n",
    "        res_on_std.append(mean_metric)\n",
    "#         print(f'for intensity:{intensity} > {mean_metric}') #chckpnt 7 with first 1 sec\n",
    "    multiple_run.append(res_on_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce4e835",
   "metadata": {},
   "outputs": [],
   "source": [
    "multiple_run = np.array(multiple_run)\n",
    "multiple_run.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa86b3f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = np.round(np.mean(multiple_run, axis=0),3)\n",
    "t1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5de2e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "t2 = np.round(np.std(multiple_run, axis=0),4)\n",
    "t2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dbdde79",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, len(t1)):\n",
    "    print(f'{intensities[i]} & {t1[i,0]} $\\\\pm$ {t2[i,0]} & {t1[i,1]} $\\\\pm$ {t2[i,1]} & {t1[i,3]} $\\\\pm$ {t2[i,3]} \\\\\\\\')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3bbc58d",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_name = ['U-Net',\n",
    "'U-Net++',\n",
    "'Siam U-Net'\n",
    "'Attention U-Net',\n",
    "'LSTM U-Net v1',\n",
    "'LSTM U-Net v2'\n",
    "'LSTM U-Net v3'\n",
    "'Trans U-Net',\n",
    "'VisTR''TeViT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c06f2d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for std:0 >[0.83690573 0.85833555 0.83802441 0.83802489]\n",
    "for std:0.1 >[0.82723017 0.86671863 0.83654147 0.83654195]\n",
    "for std:0.2 >[0.81205674 0.86474631 0.82599101 0.82599149]\n",
    "for std:0.3 >[0.8026464  0.85994068 0.81760362 0.8176041 ]\n",
    "for std:0.4 >[0.78327907 0.84819331 0.80051047 0.80051094]\n",
    "for std:0.5 >[0.77034189 0.84139687 0.7871163  0.78711677]\n",
    "for std:0.6 >[0.74281318 0.82671354 0.76420754 0.764208  ]\n",
    "for std:0.7 >[0.7144488  0.81369497 0.74036554 0.74036598]\n",
    "for std:0.8 >[0.69103701 0.80726473 0.72417577 0.72417621]\n",
    "for std:0.9 >[0.65231087 0.79418556 0.69225012 0.69225054]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c330f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean([i.mean(axis=0) for i in test_res], axis=0) #chckpnt 7 with first 1 sec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc0c9159",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "std - 0 0.83690573, 0.85833555, 0.83802441, 0.83802489 \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0540e74d",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean([i.mean(axis=0) for i in test_res], axis=0) #chckpnt 7 with first 1 sec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b076fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = {}\n",
    "for i in range(len(test_file_dir)):\n",
    "    name = test_file_dir[i].split('/')[-1]\n",
    "    \n",
    "    masks = np.array(pred_mask[i]).transpose((1,2,0))\n",
    "    masks = np.array(masks, order='F', dtype='uint8')\n",
    "    masks = mask_utils.encode(masks)\n",
    "    for msk in masks:\n",
    "        msk['counts'] = msk['counts'].decode()\n",
    "    res[name] = masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a7520ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "json.dump(res, open('pred_results_test.json', 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1fa798b",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean([i.mean(axis=0) for i in test_res], axis=0) #chckpnt 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d6c2e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean([i.mean(axis=0) for i in test_res], axis=0) #chckpnt 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc9ca617",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean([i.mean(axis=0) for i in test_res], axis=0) #chckpnt 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a6f5a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean([i.mean(axis=0) for i in test_res], axis=0) #chckpnt 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "850b6642",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean([i.mean(axis=0) for i in test_res], axis=0) #chckpnt 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af34dbc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,j in enumerate(test_file_dir):\n",
    "    print(i,j[-6:])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed44e1f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "transform = T.Compose([\n",
    "    T.ToTensor(),\n",
    "    T.Normalize([0.2316], [0.2038]), #mean #standard deviation\n",
    "#     AddGaussianNoise(mean=0., std=std)\n",
    "])\n",
    "avg_res2 = []\n",
    "for num in tqdm(range(len(test_img_path)), leave = False):\n",
    "#     start = time.time()\n",
    "    output, vid_length = test_model(test_img_path, num, model, n_frames= 36)\n",
    "#     end = time.time()\n",
    "#     print(vid_length/(end-start))\n",
    "#     pred_mask.append(output)\n",
    "#     print(len(output))\n",
    "    res = []\n",
    "\n",
    "#     for j in range(39):\n",
    "    for j in range(vid_length):\n",
    "        GT = np.array(Image.open(test_msk_path[num][j]))/255\n",
    "        SR = output[j]\n",
    "\n",
    "        res.append(get_metric(SR, GT))\n",
    "    res = np.array(res)\n",
    "    avg_res2.append(res.mean(axis=0))\n",
    "    print(f'{num}:',res.mean(axis=0))\n",
    "print(f'{num}:',np.mean(avg_res2, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf0df960",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  area mm2/ a pixel\n",
    "const = (30/448)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f7b67b1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def put_text(frame, name):\n",
    "    cv2.putText(frame,\n",
    "            name, (0, 440),\n",
    "            0,\n",
    "            1,\n",
    "            color =(255, 255, 255),\n",
    "            thickness=2,\n",
    "            lineType=cv2.LINE_AA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3141101",
   "metadata": {},
   "outputs": [],
   "source": [
    "num = 5\n",
    "output, vid_length = test_model(test_img_path, num, model, n_frames= 36)\n",
    "output = get_filtered_mask(output)\n",
    "\n",
    "clip = test_img_path[num]\n",
    "op = []\n",
    "\n",
    "frameSize = (336, 448) # width x height\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "name = test_file_dir[num].split('/')[-1].split('_')[-1]\n",
    "print(name)\n",
    "out = cv2.VideoWriter(f'{name}_vistr.avi', \n",
    "                      fourcc, 15,\n",
    "                      frameSize,)\n",
    "#                       isColor = False)\n",
    "for i in tqdm(range(len(output))):\n",
    "    \n",
    "    img = Image.open(clip[i]) #frame\n",
    "\n",
    "    msk = Image.open(test_msk_path[num][i]) #ground Truth\n",
    "    temp = create_pred_video(img, msk, 'GT') #Green\n",
    "    out_frame = create_pred_video(temp,output[i], 'Pred') #Red\n",
    "#     out_frame = out_frame[:224]\n",
    "\n",
    "    area = np.sum(output[i])*const\n",
    "\n",
    "    put_text(out_frame, f'CSA={round(area,2)}')\n",
    "    op.append(out_frame)\n",
    "    out.write(out_frame)\n",
    "\n",
    "out.release()\n",
    "# l = np.linspace(0,len(op),6, endpoint=False)\n",
    "# l = [0,7,14,21,28,35]\n",
    "\n",
    "# plt.figure(figsize=(16,7))\n",
    "# # plt.figure(figsize=(16,13))\n",
    "# for i in range(len(l)):\n",
    "#     plt.subplot(2,3,i+1)\n",
    "# #     print(l[i])\n",
    "#     plt.axis(\"off\")\n",
    "#     plt.imshow(cv2.cvtColor(op[int(l[i])], cv2.COLOR_BGR2RGB))\n",
    "#     plt.title(f'frame-{int(l[i])}', fontsize=15)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bae5b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "for frame in output:\n",
    "    area = np.sum(frame)*const\n",
    "    if not isinstance(frame, np.ndarray): frame = np.array(frame)\n",
    "    if frame.dtype!='uint8': frame= (frame*255).astype(np.uint8)\n",
    "    if(len(frame.shape)<3): frame = cv2.cvtColor(frame,cv2.COLOR_GRAY2RGB)\n",
    "    put_text(frame, f'CSA={round(area,2)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d22fd98f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50746a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "area = np.sum(SR)*const\n",
    "area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bab0ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "SR.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eebc504e",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_res = np.round(avg_res,3)\n",
    "avg_res2 = np.round(avg_res2,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04da5c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(avg_res)):\n",
    "    print(f'{i+1} & {avg_res2[i][0]} & {avg_res2[i][1]}  & {avg_res2[i][3]} & {avg_res[i][0]} & {avg_res[i][1]}  & {avg_res[i][3]}')\n",
    "print(f'mean & {np.mean(avg_res2[:,0])} & {np.mean(avg_res2[:,1])} & {np.mean(avg_res2[:,3])} & {np.mean(avg_res[:,0])} & {np.mean(avg_res[:,1])} & {np.mean(avg_res[:,3])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a819d55a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,j in enumerate(test_file_dir):\n",
    "    print(j,i)\n",
    "num = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26847bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_dir = sorted(glob.glob('../Dissertation/aster_updated_data_22_01_2022/full/*'))\n",
    "\n",
    "test_full_path = []\n",
    "\n",
    "for path in file_dir:\n",
    "    test_full_path.append(sorted(glob.glob(path+'/*_0001_IMAGES/images/*.jpg'), key=key_func))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76dde67a",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = T.Compose([\n",
    "T.ToTensor(),\n",
    "T.Normalize([0.2316], [0.2038]), #mean #standard deviation\n",
    "#     AddGaussianNoise(mean=0., std=std)\n",
    "])\n",
    "\n",
    "output, vid_length = test_model(test_full_path, num, model, num_frames)\n",
    "pred_masks_vistr = get_filtered_mask(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be0f4afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../TeViT-main/results.json', 'r') as f:\n",
    "    full_data = json.load(f)\n",
    "f.close()\n",
    "pred_masks = []\n",
    "for i, pred in enumerate(full_data):\n",
    "#     assert pred['video_id'] == truth['video_id'] , \"Video ID should match\"\n",
    "#     filename = data['video_id']\n",
    "    temp = mask_utils.decode(pred['segmentations']).transpose((2,0,1))\n",
    "    pred_masks += [msk for msk in temp]\n",
    "pred_masks_tevit = get_filtered_mask(pred_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b42fb24b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('pred_results_lstm.json', 'r') as f:\n",
    "    full_data = json.load(f)\n",
    "f.close()\n",
    "pred_masks_lstm = []\n",
    "\n",
    "temp = mask_utils.decode(full_data['144344']).transpose((2,0,1))\n",
    "pred_masks_lstm += [msk for msk in temp]\n",
    "# pred_masks_lstm = get_filtered_mask(pred_masks_lstm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f0de722",
   "metadata": {},
   "outputs": [],
   "source": [
    "clip = test_full_path[num]\n",
    "frameSize = (336*3, 448) # width x height\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "name = test_file_dir[num].split('/')[-1].split('_')[-1]\n",
    "out = cv2.VideoWriter(f'{name}_filter.avi', \n",
    "                      fourcc, 15,\n",
    "                      frameSize,)\n",
    "#                       isColor = False)\n",
    "\n",
    "for i in range(len(pred_masks_tevit)):\n",
    "    tmp = np.zeros((448, 336*3,3)).astype(np.uint8)\n",
    "    \n",
    "    img = Image.open(clip[i]) #frame\n",
    "    \n",
    "    if i < len(test_msk_path[num]):\n",
    "        msk = Image.open(test_msk_path[num][i]) #ground Truth\n",
    "        temp = create_pred_video(img, msk, 'GT') #Green\n",
    "        temp2 = create_pred_video(img, msk, 'GT') #Green\n",
    "        temp3 = create_pred_video(img, msk, 'GT') #Green\n",
    "        out_frame = create_pred_video(temp,pred_masks_vistr[i], 'Pred') #Red\n",
    "        out_frame2 = create_pred_video(temp2,pred_masks_tevit[i], 'Pred') #Red\n",
    "        out_frame3 = create_pred_video(temp3,pred_masks_lstm[i], 'Pred') #Red\n",
    "    else:\n",
    "        out_frame = create_pred_video(img,pred_masks_vistr[i], 'Pred') #Red\n",
    "        out_frame2 = create_pred_video(img,pred_masks_tevit[i], 'Pred') #Red\n",
    "        out_frame3 = create_pred_video(img,pred_masks_lstm[i], 'Pred') #Red\n",
    "#     out_frame = create_pred_video(temp,pred_mask[0][i], 'Pred') #Red\n",
    "    put_text(out_frame, 'VisTR')\n",
    "    put_text(out_frame2, 'TeViT')\n",
    "    put_text(out_frame3, 'LSTM V1')\n",
    "    tmp[:,:336,:] = out_frame\n",
    "    tmp[:,336:336*2,:] = out_frame2\n",
    "    tmp[:,336*2:,:] = out_frame3\n",
    "    out.write(tmp)\n",
    "\n",
    "out.release()\n",
    "print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd3365b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(cv2.putText(out_frame,\n",
    "        'VisTR', (0, 440),\n",
    "        0,\n",
    "        1,\n",
    "        color =(255, 255, 255),\n",
    "        thickness=2,\n",
    "        lineType=cv2.LINE_AA))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b37f881",
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_dir = sorted(glob.glob('../Dissertation/aster_updated_data_22_01_2022/NORMAL WRIST MEDIAN 1.5CM/*'))\n",
    "file_dir = sorted(glob.glob('../Dissertation/aster_updated_data_22_01_2022/SEVERE CTS WRIST 1.5CM/*'))\n",
    "# file_dir = sorted(glob.glob('../Dissertation/aster_updated_data_22_01_2022/CTS 1.5CM AND 3CM/*'))\n",
    "# file_dir = sorted(glob.glob('../Dissertation/aster_updated_data_22_01_2022/full/*'))[:1]\n",
    "\n",
    "img_path = []\n",
    "msk_path = []\n",
    "\n",
    "for path in file_dir:\n",
    "#     img_path.append(sorted(glob.glob(path+'/*.jpg'), key=key_func))\n",
    "    img_path.append(sorted(glob.glob(path+'/frames/*.jpg'), key=key_func))\n",
    "#     img_path.append(sorted(glob.glob(path+'/frames2/*.jpg'), key=key_func))\n",
    "#     img_path.append(sorted(glob.glob(path+'/*_0001_IMAGES/*.jpg'), key=key_func))\n",
    "len(img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b27e5a64",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Image.open(img_path[0][76]).size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aba1f89",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_res = []\n",
    "pred_mask = []\n",
    "for num in tqdm(range(len(img_path))):\n",
    "    start = time.time()\n",
    "    output, vid_length = test_model(img_path, num, model, n_frames = 36)\n",
    "    end = time.time()\n",
    "#     print(vid_length/(end-start))\n",
    "#     break\n",
    "    pred_mask.append(output)\n",
    "    print(vid_length/(end-start))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f28ad918",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(pred_mask[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "525298e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_mask[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b03df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = {}\n",
    "for i in range(len(file_dir)):\n",
    "    name = file_dir[i].split('/')[-1]\n",
    "    \n",
    "    masks = np.array(pred_mask[i]).transpose((1,2,0))\n",
    "    masks = np.array(masks, order='F', dtype='uint8')\n",
    "    masks = mask_utils.encode(masks)\n",
    "    for msk in masks:\n",
    "        msk['counts'] = msk['counts'].decode()\n",
    "    res[name] = masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b581b23a",
   "metadata": {},
   "outputs": [],
   "source": [
    "json.dump(res, open('pred_results_NWM.json', 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "618e042d",
   "metadata": {},
   "outputs": [],
   "source": [
    "vid_num = 1\n",
    "name = file_dir[vid_num].split('/')[-1]\n",
    "frameSize = (336, 448) # width x height\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "out = cv2.VideoWriter(str(vid_num)+'_'+name+'.avi', \n",
    "                      fourcc, 15,\n",
    "                      frameSize,)\n",
    "#                       isColor = False)\n",
    "\n",
    "for i in range(len(img_path[vid_num])):\n",
    "    \n",
    "    img = Image.open(img_path[vid_num][i]) #frame\n",
    "    out_frame = create_pred_video(img,pred_mask[vid_num][i], 'Pred')\n",
    "    out.write(out_frame)\n",
    "\n",
    "out.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "388315b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Image.open(test_img_path[num][0])\n",
    "y = Image.open(test_msk_path[num][0])\n",
    "# create_pred_video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd65e367",
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = sorted(glob.glob('../Dissertation/aster_updated_data_22_01_2022/full/*'))\n",
    "test_full_vid = []\n",
    "for path in paths:\n",
    "    test_full_vid.append(sorted(glob.glob(path + '/*_0001_IMAGES/images/*.jpg'), key=key_func))\n",
    "# test_full_vid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0396b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert image shape into 448,336\n",
    "for img_paths in tqdm(test_full_vid, total=len(test_full_vid)):\n",
    "    for img_path in img_paths:\n",
    "#         print(img_path)\n",
    "#         break\n",
    "        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "        if img.shape != (448,336):\n",
    "            cv2.imwrite(img_path, img[4:452,3:339])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48aa8f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_mask = []\n",
    "start = time.time()\n",
    "for num in tqdm(range(len(test_full_vid))):\n",
    "    output = test_model(test_full_vid, num, model, n_frames = 36)\n",
    "    p_mask.append(output)\n",
    "    \n",
    "end = time.time()\n",
    "print('time taken:',end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a29fefd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test_full_vid[0])/(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9480ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c2afda",
   "metadata": {},
   "outputs": [],
   "source": [
    "frameSize = (336, 448) # width x height\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "out = cv2.VideoWriter('output_VisTR_144344_full.avi', \n",
    "                      fourcc, 15,\n",
    "                      frameSize,)\n",
    "#                       isColor = False)\n",
    "\n",
    "for i in range(len(test_full_vid[0])):\n",
    "    \n",
    "    img = Image.open(test_full_vid[0][i]) #frame\n",
    "#     msk = Image.open(test_msk_path[5][i]) #ground Truth\n",
    "#     temp = create_pred_video(img, msk, 'GT')\n",
    "    out_frame = create_pred_video(img,p_mask[0][i], 'Pred')\n",
    "    out.write(out_frame)\n",
    "\n",
    "out.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a7e405f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_frames(path):\n",
    "    # Read the video from specified path\n",
    "    frame_list = []\n",
    "    cam = cv2.VideoCapture(path)\n",
    "    nw = []\n",
    "    while(True):\n",
    "        # reading from frame\n",
    "        ret,frame = cam.read()\n",
    "        if ret:\n",
    "            frame_list.append(frame)\n",
    "        else:\n",
    "            break\n",
    "    return frame_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d759b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "  \n",
    "nw = get_frames(\"10_NOR0016_WRIST-N_20221122_121300.avi\")\n",
    "cts = get_frames(\"5_005_CTS_20221031_133239.avi\")\n",
    "s_cts = get_frames(\"5_SEV0015_WRIST-CTS_20230109_145944.avi\")\n",
    "print(len(nw), len(cts), len(s_cts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39fc0c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "frameSize = (336*3, 448) # width x height\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "name = 'Classification'\n",
    "out = cv2.VideoWriter(f'{name}.avi', \n",
    "                      fourcc, 5,\n",
    "                      frameSize,)\n",
    "#                       isColor = False)\n",
    "\n",
    "for i in range(min(len(nw), len(cts), len(s_cts))):\n",
    "    tmp = np.zeros((448, 336*3,3)).astype(np.uint8)\n",
    "    \n",
    "    put_text(nw[i], 'Normal Wrist')\n",
    "    put_text(cts[i], 'Mild CTS')\n",
    "    put_text(s_cts[i], 'Severe CTS')\n",
    "    tmp[:,:336,:] = nw[i]\n",
    "    tmp[:,336:336*2,:] = cts[i]\n",
    "    tmp[:,336*2:,:] = s_cts[i]\n",
    "    out.write(tmp)\n",
    "\n",
    "out.release()\n",
    "print(name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
